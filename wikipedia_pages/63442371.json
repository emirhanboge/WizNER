{
    "id": "63442371",
    "revid": "42267714",
    "url": "https://en.wikipedia.org/wiki?curid=63442371",
    "title": "Regulation of algorithms",
    "text": "Regulation of algorithms, or algorithmic regulation, is the creation of laws, rules and public sector policies for promotion and &lt;a href=\"regulation\"&gt;regulation&lt;/a&gt; of &lt;a href=\"algorithm\"&gt;algorithm&lt;/a&gt;s, particularly in &lt;a href=\"artificial%20intelligence\"&gt;artificial intelligence&lt;/a&gt; and &lt;a href=\"machine%20learning\"&gt;machine learning&lt;/a&gt;. For the subset of AI algorithms, the term &lt;a href=\"regulation%20of%20artificial%20intelligence\"&gt;regulation of artificial intelligence&lt;/a&gt; is used. The regulatory and policy landscape for artificial intelligence (AI) is an emerging issue in jurisdictions globally, including in the European Union. Regulation of AI is considered necessary to both encourage AI and manage associated risks, but challenging. Another emerging topic is the regulation of &lt;a href=\"blockchain\"&gt;blockchain&lt;/a&gt; algorithms and is mentioned alongside with regulation of AI algorithms. Many countries have enacted &lt;a href=\"High-frequency_trading%23Regulation_and_enforcement\"&gt;regulations of high frequency trades&lt;/a&gt;, which is shifting due to technological progress into the realm of AI algorithms. \nThe motivation for regulation of algorithms is the apprehension of &lt;a href=\"AI_control_problem\"&gt;losing control over the algorithms&lt;/a&gt;, whose impact on human life increases. Multiple countries have already introduced regulations in case of automated credit score calculation\u2014&lt;a href=\"right%20to%20explanation\"&gt;right to explanation&lt;/a&gt; is mandatory for those algorithms. Bias, transparency, and ethics concerns have emerged with respect to the use of algorithms in diverse domains ranging from criminal justice to healthcare\u2014many fear that artificial intelligence could replicate existing social inequalities along race, class, gender, and sexuality lines. \nRegulation of artificial intelligence.\nPublic discussion.\nIn 2016, &lt;a href=\"Joy%20Buolamwini\"&gt;Joy Buolamwini&lt;/a&gt; founded &lt;a href=\"Algorithmic%20Justice%20League\"&gt;Algorithmic Justice League&lt;/a&gt; after a personal experience with biased facial detection software in order to raise awareness of the social implications of artificial intelligence through art and research.\nIn 2017 &lt;a href=\"Elon%20Musk\"&gt;Elon Musk&lt;/a&gt; advocated regulation of algorithms in the context of the &lt;a href=\"existential%20risk%20from%20artificial%20general%20intelligence\"&gt;existential risk from artificial general intelligence&lt;/a&gt;. According to &lt;a href=\"National%20Public%20Radio\"&gt;NPR&lt;/a&gt;, the &lt;a href=\"Tesla%2C%20Inc.\"&gt;Tesla&lt;/a&gt; CEO was \"clearly not thrilled\" to be advocating for government scrutiny that could impact his own industry, but believed the risks of going completely without oversight are too high: \"Normally the way regulations are set up is when a bunch of bad things happen, there's a public outcry, and after many years a regulatory agency is set up to regulate that industry. It takes forever. That, in the past, has been bad but not something which represented a fundamental risk to the existence of civilisation.\" \nIn response, some politicians expressed skepticism about the wisdom of regulating a technology that is still in development. Responding both to Musk and to February 2017 proposals by European Union lawmakers to regulate AI and robotics, Intel CEO &lt;a href=\"Brian%20Krzanich\"&gt;Brian Krzanich&lt;/a&gt; has argued that artificial intelligence is in its infancy and that it is too early to regulate the technology. Instead of trying to regulate the technology itself, some scholars suggest to rather develop common norms including requirements for the testing and transparency of algorithms, possibly in combination with some form of warranty. One suggestion has been for the development of a global governance board to regulate AI development. In 2020, the European Union published its draft strategy paper for promoting and regulating AI.\n&lt;a href=\"Algorithmic%20tacit%20collusion\"&gt;Algorithmic tacit collusion&lt;/a&gt; is a legally dubious antitrust practise committed by means of algorithms, which the courts are not able to prosecute. This danger concerns scientists and regulators in EU, US and beyond. &lt;a href=\"European%20Commissioner\"&gt;European Commissioner&lt;/a&gt; &lt;a href=\"Margrethe%20Vestager\"&gt;Margrethe Vestager&lt;/a&gt; mentioned an early example of algorithmic tacit collusion in her speech on \"Algorithms and Collusion\" on March 16, 2017, described as follow:\n\"A few years ago, two companies were selling a textbook called The Making of a Fly. One of those sellers used an algorithm which essentially matched its rival\u2019s price. That rival had an algorithm which always set a price 27% higher than the first. The result was that prices kept spiralling upwards, until finally someone noticed what was going on, and adjusted the price manually. By that time, the book was selling \u2013 or rather, not selling \u2013 for 23 million dollars a copy.\"\nIn 2018, the Netherlands employed an algorithmic system SyRI (Systeem Risico Indicatie) to detect citizens perceived being high risk for committing &lt;a href=\"welfare%20fraud\"&gt;welfare fraud&lt;/a&gt;, which quietly flagged thousands of people to investigators. This caused a public protest. The district court of Hague shut down SyRI referencing &lt;a href=\"Article%208%20of%20the%20European%20Convention%20on%20Human%20Rights\"&gt;Article 8 of the European Convention on Human Rights&lt;/a&gt; (ECHR).\nIn 2020, algorithms assigning exam grades to students in the UK sparked open protest under the banner \"Fuck the algorithm.\" This protest was successful and the grades were taken back.\nImplementation.\nAI law and regulations can be divided into three main topics, namely governance of autonomous intelligence systems, responsibility and accountability for the systems, and privacy and safety issues. The development of public sector strategies for management and regulation of AI has been increasingly deemed necessary at the local, national, and international levels and in a variety of fields, from public service management to law enforcement, the financial sector, robotics, the military, and international law. There are many concerns that there is not enough visibility and monitoring of AI in these sectors. In the financial sector, for example, there have been calls for the Consumer Financial Protection Bureau to more closely examine source code and algorithms when conducting audits of financial institutions' non-public data.\nIn the United States, on January 7, 2019, following an Executive Order on 'Maintaining American Leadership in Artificial Intelligence', the White House\u2019s Office of Science and Technology Policy released a draft \"Guidance for Regulation of Artificial Intelligence Applications\", which includes ten principles for United States agencies when deciding whether and how to regulate AI. In response, the National Institute of Standards and Technology has released a position paper, the National Security Commission on Artificial Intelligence has published an interim report, and the Defense Innovation Board has issued recommendations on the ethical use of AI. \nIn 2016, China published a position paper questioning the adequacy of existing international law to address the eventuality of &lt;a href=\"Lethal%20autonomous%20weapon\"&gt;fully autonomous weapons&lt;/a&gt;, becoming the first permanent member of the U.N. &lt;a href=\"Security%20Council\"&gt;Security Council&lt;/a&gt; to broach the issue, and leading to &lt;a href=\"Artificial%20intelligence%20arms%20race\"&gt;proposals for global regulation&lt;/a&gt;. In the United States, steering on regulating security-related AI is provided by the National Security Commission on Artificial Intelligence.\nRegulation of blockchain algorithms.\n&lt;a href=\"Blockchain\"&gt;Blockchain&lt;/a&gt; systems provide transparent and fixed records of transactions and hereby contradict the goal of the European &lt;a href=\"GDPR\"&gt;GDPR&lt;/a&gt;, which is to give individuals full control of their private data.\nBy implementing the &lt;a href=\"Decree%20on%20Development%20of%20Digital%20Economy\"&gt;Decree on Development of Digital Economy&lt;/a&gt;, &lt;a href=\"Belarus\"&gt;Belarus&lt;/a&gt; has become the first-ever country to legalize &lt;a href=\"smart%20contract\"&gt;smart contract&lt;/a&gt;s. Belarusian lawyer Denis Aleinikov is considered to be the author of a smart contract legal concept introduced by the decree. There are strong arguments that the existing US state laws are already a sound basis for the smart contracts' enforceability \u2014 &lt;a href=\"Arizona\"&gt;Arizona&lt;/a&gt;, &lt;a href=\"Nevada\"&gt;Nevada&lt;/a&gt;, &lt;a href=\"Ohio\"&gt;Ohio&lt;/a&gt; and &lt;a href=\"Tennessee\"&gt;Tennessee&lt;/a&gt; have amended their laws specifically to allow for the enforceability of blockchain-based contracts nevertheless.\nIn popular culture.\nIn 1942, author &lt;a href=\"Isaac%20Asimov\"&gt;Isaac Asimov&lt;/a&gt; addressed regulation of algorithms by introducing the fictional &lt;a href=\"Three%20Laws%20of%20Robotics\"&gt;Three Laws of Robotics&lt;/a&gt;:\nThe main alternative to regulation is a ban, and the banning of algorithms is presently highly unlikely. However, in &lt;a href=\"Frank%20Herbert\"&gt;Frank Herbert&lt;/a&gt;'s &lt;a href=\"Dune%20%28franchise%29\"&gt;\"Dune\" universe&lt;/a&gt;, &lt;a href=\"Organizations_of_the_Dune_universe%23Thinking_machines\"&gt;thinking machines&lt;/a&gt; is a collective term for &lt;a href=\"artificial%20intelligence\"&gt;artificial intelligence&lt;/a&gt;, which were completely destroyed and banned after a revolt known as the &lt;a href=\"Butlerian%20Jihad\"&gt;Butlerian Jihad&lt;/a&gt;:\nJIHAD, BUTLERIAN: (see also Great Revolt) \u2014 the crusade against computers, thinking machines, and conscious robots begun in 201 B.G. and concluded in 108 B.G. Its chief commandment remains in the &lt;a href=\"Orange%20Catholic%20Bible\"&gt;O.C. Bible&lt;/a&gt; as \"Thou shalt not make a machine in the likeness of a human mind.\""
}