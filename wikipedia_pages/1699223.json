{
    "id": "1699223",
    "revid": "40874009",
    "url": "https://en.wikipedia.org/wiki?curid=1699223",
    "title": "Continuous uniform distribution",
    "text": " 1 &amp;\\text{for } t = 0\n \\end{cases}&lt;/math&gt;\n |char = formula_1\nIn &lt;a href=\"probability%20theory\"&gt;probability theory&lt;/a&gt; and &lt;a href=\"statistics\"&gt;statistics&lt;/a&gt;, the continuous uniform distribution or rectangular distribution is a family of &lt;a href=\"Symmetric%20distribution\"&gt;symmetric&lt;/a&gt; &lt;a href=\"probability%20distributions\"&gt;probability distributions&lt;/a&gt;. The distribution describes an experiment where there is an arbitrary outcome that lies between certain bounds. The bounds are defined by the parameters, \"a\" and \"b\", which are the minimum and maximum values. The interval can either be &lt;a href=\"Closed%20interval\"&gt;closed&lt;/a&gt; (e.g. [a, b]) or &lt;a href=\"Open%20Interval\"&gt;open&lt;/a&gt; (e.g. (a, b)). Therefore, the distribution is often abbreviated \"U\" (\"a\", \"b\"), where U stands for uniform distribution. The difference between the bounds defines the interval length; all &lt;a href=\"interval%20%28mathematics%29\"&gt;interval&lt;/a&gt;s of the same length on the distribution's &lt;a href=\"Support%20%28mathematics%29\"&gt;support&lt;/a&gt; are equally probable. It is the &lt;a href=\"maximum%20entropy%20probability%20distribution\"&gt;maximum entropy probability distribution&lt;/a&gt; for a &lt;a href=\"random%20variable\"&gt;random variable&lt;/a&gt; \"X\" under no constraint other than that it is contained in the distribution's support.\nDefinitions.\nProbability density function.\nThe &lt;a href=\"probability%20density%20function\"&gt;probability density function&lt;/a&gt; of the continuous uniform distribution is:\nThe values of \"f\"(\"x\") at the two boundaries \"a\" and \"b\" are usually unimportant because they do not alter the values of the integrals of over any interval, nor of or any higher moment. Sometimes they are chosen to be zero, and sometimes chosen to be . The latter is appropriate in the context of estimation by the method of &lt;a href=\"maximum%20likelihood\"&gt;maximum likelihood&lt;/a&gt;. In the context of &lt;a href=\"Fourier%20analysis\"&gt;Fourier analysis&lt;/a&gt;, one may take the value of \"f\"(\"a\") or \"f\"(\"b\") to be , since then the inverse transform of many &lt;a href=\"integral%20transform\"&gt;integral transform&lt;/a&gt;s of this uniform function will yield back the function itself, rather than a function which is equal \"&lt;a href=\"almost%20everywhere\"&gt;almost everywhere&lt;/a&gt;\", i.e. except on a set of points with zero &lt;a href=\"measure%20theory\"&gt;measure&lt;/a&gt;. Also, it is consistent with the &lt;a href=\"sign%20function\"&gt;sign function&lt;/a&gt; which has no such ambiguity.\nGraphically, the &lt;a href=\"probability%20density%20function\"&gt;probability density function&lt;/a&gt; is portrayed as a rectangle where is the base and is the height. As the distance between a and b increases, the density at any particular value within the distribution boundaries decreases. Since the &lt;a href=\"probability%20density%20function\"&gt;probability density function&lt;/a&gt; integrates to 1, the height of the probability density function decreases as the base length increases.\nIn terms of mean \"\u03bc\" and variance \"\u03c3\"2, the probability density may be written as:\nCumulative distribution function.\nThe &lt;a href=\"cumulative%20distribution%20function\"&gt;cumulative distribution function&lt;/a&gt; is:\nIts inverse is:\nand the inverse is:\nExample 1. Using the Uniform Cumulative Distribution Function.\nFor random variable \nFind formula_8:\nIn graphical representation of uniform distribution function [f(x) vs x], the area under the curve within the specified bounds displays the probability (shaded area is depicted as a rectangle). For this specific example above, the base would be and the height would be .\nExample 2. Using the Uniform Cumulative Distribution Function (Conditional).\nFor random variable \nFind formula_11:\nThe example above is for a conditional probability case for the uniform distribution: given is true, what is the probability that . Conditional probability changes the sample space so a new interval length has to be calculated, where is 23 and is 8. The graphical representation would still follow Example 1, where the area under the curve within the specified bounds displays the probability and the base of the rectangle would be and the height .\nGenerating functions.\nMoment-generating function.\nThe &lt;a href=\"moment-generating%20function\"&gt;moment-generating function&lt;/a&gt; is:\nfrom which we may calculate the &lt;a href=\"raw%20moments\"&gt;raw moments&lt;/a&gt; \"m\" \"k\"\nFor the special case \"a\"\u00a0=\u00a0\u2013\"b\", that is, for\nthe moment-generating functions reduces to the simple form\nFor a &lt;a href=\"random%20variable\"&gt;random variable&lt;/a&gt; following this distribution, the &lt;a href=\"expected%20value\"&gt;expected value&lt;/a&gt; is then \"m\"1 = (\"a\"\u00a0+\u00a0\"b\")/2 and the &lt;a href=\"variance\"&gt;variance&lt;/a&gt; is\n\"m\"2\u00a0\u2212\u00a0\"m\"12 = (\"b\"\u00a0\u2212\u00a0\"a\")2/12.\nCumulant-generating function.\nFor , the \"n\"th &lt;a href=\"cumulant\"&gt;cumulant&lt;/a&gt; of the uniform distribution on the interval is \"B\"\"n\"/\"n\", where \"B\"\"n\" is the \"n\"th &lt;a href=\"Bernoulli%20number\"&gt;Bernoulli number&lt;/a&gt;.\nStandard uniform.\nRestricting formula_19 and formula_20, the resulting distribution \"U\"(0,1) is called a standard uniform distribution.\nOne interesting property of the standard uniform distribution is that if \"u\"1 has a standard uniform distribution, then so does 1-\"u\"1. This property can be used for generating &lt;a href=\"antithetic%20variates\"&gt;antithetic variates&lt;/a&gt;, among other things. In other words, this property is known as the &lt;a href=\"inversion%20method\"&gt;inversion method&lt;/a&gt; where the continuous standard uniform distribution can be used to generate &lt;a href=\"Statistical%20randomness\"&gt;random numbers&lt;/a&gt; for any other continuous distribution. If is a uniform random number with standard uniform distribution (0,1), then formula_21 generates a random number from any continuous distribution with the specified &lt;a href=\"cumulative%20distribution%20function\"&gt;cumulative distribution function&lt;/a&gt; .\nRelationship to other functions.\nAs long as the same conventions are followed at the transition points, the probability density function may also be expressed in terms of the &lt;a href=\"Heaviside%20step%20function\"&gt;Heaviside step function&lt;/a&gt;:\nor in terms of the &lt;a href=\"rectangle%20function\"&gt;rectangle function&lt;/a&gt;\nThere is no ambiguity at the transition point of the &lt;a href=\"sign%20function\"&gt;sign function&lt;/a&gt;. Using the half-maximum convention at the transition points, the uniform distribution may be expressed in terms of the sign function as:\nProperties.\nMoments.\nThe mean (first &lt;a href=\"Moment%20%28mathematics%29\"&gt;moment&lt;/a&gt;) of the distribution is:\nThe second moment of the distribution is:\nIn general, the \"n\"-th moment of the uniform distribution is:\nThe variance (second &lt;a href=\"central%20moment\"&gt;central moment&lt;/a&gt;) is:\nOrder statistics.\nLet \"X\"1, ..., \"X\"\"n\" be an &lt;a href=\"i.i.d.\"&gt;i.i.d.&lt;/a&gt; sample from \"U\"(0,1). Let \"X\"(\"k\") be the \"k\"th &lt;a href=\"order%20statistic\"&gt;order statistic&lt;/a&gt; from this sample. Then the probability distribution of \"X\"(\"k\") is a &lt;a href=\"Beta%20distribution\"&gt;Beta distribution&lt;/a&gt; with parameters \"k\" and . The expected value is\nThis fact is useful when making &lt;a href=\"Q%E2%80%93Q%20plot\"&gt;Q\u2013Q plot&lt;/a&gt;s.\nThe variances are\nSee also: \nUniformity.\nThe probability that a uniformly distributed random variable falls within any interval of fixed length is independent of the location of the interval itself (but it is dependent on the interval size), so long as the interval is contained in the distribution's support.\nTo see this, if \"X\" ~ U(\"a\",\"b\") and [\"x\", \"x\"+\"d\"] is a subinterval of [\"a\",\"b\"] with fixed \"d\" &gt; 0, then\nGeneralization to Borel sets.\nThis distribution can be generalized to more complicated sets than intervals. If \"S\" is a &lt;a href=\"Borel%20set\"&gt;Borel set&lt;/a&gt; of positive, finite measure, the uniform probability distribution on \"S\" can be specified by defining the pdf to be zero outside \"S\" and constantly equal to 1/\"K\" on \"S\", where \"K\" is the &lt;a href=\"Lebesgue%20measure\"&gt;Lebesgue measure&lt;/a&gt; of \"S\".\nStatistical inference.\nEstimation of parameters.\nEstimation of maximum.\nMinimum-variance unbiased estimator.\nGiven a uniform distribution on [0,\u00a0\"b\"] with unknown \"b,\" the\n&lt;a href=\"UMVU\"&gt;minimum-variance unbiased estimator (UMVUE)&lt;/a&gt; for the maximum is given by\nwhere \"m\" is the &lt;a href=\"sample%20maximum\"&gt;sample maximum&lt;/a&gt; and \"k\" is the &lt;a href=\"sample%20size\"&gt;sample size&lt;/a&gt;, sampling without replacement (though this distinction almost surely makes no difference for a continuous distribution). This follows for the same reasons as &lt;a href=\"Uniform%20distribution%20%28discrete%29%23Estimation%20of%20maximum\"&gt;estimation for the discrete distribution&lt;/a&gt;, and can be seen as a very simple case of &lt;a href=\"maximum%20spacing%20estimation\"&gt;maximum spacing estimation&lt;/a&gt;. This problem is commonly known as the &lt;a href=\"German%20tank%20problem\"&gt;German tank problem&lt;/a&gt;, due to application of maximum estimation to estimates of German tank production during &lt;a href=\"World%20War%20II\"&gt;World War II&lt;/a&gt;.\nMaximum likelihood estimator.\nThe &lt;a href=\"maximum%20likelihood\"&gt;maximum likelihood&lt;/a&gt; estimator is given by:\nwhere \"m\" is the &lt;a href=\"sample%20maximum\"&gt;sample maximum&lt;/a&gt;, also denoted as formula_34 the maximum &lt;a href=\"order%20statistic\"&gt;order statistic&lt;/a&gt; of the sample.\nMethod of moment estimator.\nThe &lt;a href=\"Method%20of%20moments%20%28statistics%29\"&gt;method of moments&lt;/a&gt; estimator is given by:\nwhere formula_36 is the sample mean.\nEstimation of midpoint.\nThe midpoint of the distribution (\"a\"\u00a0+\u00a0\"b\")\u00a0/\u00a02 is both the mean and the median of the uniform distribution. Although both the sample mean and the sample median are &lt;a href=\"unbiased%20estimator\"&gt;unbiased estimator&lt;/a&gt;s of the midpoint, neither is as &lt;a href=\"efficiency%20%28statistics%29\"&gt;efficient&lt;/a&gt; as the sample &lt;a href=\"mid-range\"&gt;mid-range&lt;/a&gt;, i.e. the arithmetic mean of the sample maximum and the sample minimum, which is the &lt;a href=\"UMVU\"&gt;UMVU&lt;/a&gt; estimator of the midpoint (and also the &lt;a href=\"maximum%20likelihood%20estimate\"&gt;maximum likelihood estimate&lt;/a&gt;).\nConfidence interval.\nFor the maximum.\nLet \"X\"1, \"X\"2, \"X\"3, ..., \"X\"\"n\" be a sample from formula_37 where \"L\" is the population maximum. Then \"X\"(\"n\") = max( \"X\"1, \"X\"2, \"X\"3, ..., \"X\"\"n\" ) has the Lebesgue-Borel-density formula_38 \nThe confidence interval given before is mathematically incorrect, as formula_40 cannot be solved for formula_41 without knowledge of formula_42. However one can solve \n formula_43 for formula_44 for any unknown but valid formula_42,\none then chooses the smallest formula_46 possible satisfying the condition above. Note that the interval length depends upon the random variable formula_47.\nOccurrence and applications.\nThe probabilities for uniform distribution function are simple to calculate due to the simplicity of the function form. Therefore, there are various applications that this distribution can be used for as shown below: hypothesis testing situations, random sampling cases, finance, etc. Furthermore, generally, experiments of physical origin follow a uniform distribution (e.g. emission of radioactive &lt;a href=\"Radioactive%20decay\"&gt;particles&lt;/a&gt;). However, it is important to note that in any application, there is the unchanging assumption that the probability of falling in an interval of fixed length is constant.\nEconomics example for uniform distribution.\nIn the field of economics, usually &lt;a href=\"demand\"&gt;demand&lt;/a&gt; and &lt;a href=\"wikt%3ASpecial%3ASearch/replenishment\"&gt;replenishment&lt;/a&gt; may not follow the expected normal distribution. As a result, other distribution models are used to better predict probabilities and trends such as &lt;a href=\"Bernoulli%20process\"&gt;Bernoulli process&lt;/a&gt;. But according to Wanke (2008), in the particular case of investigating &lt;a href=\"Lead%20time\"&gt;lead-time&lt;/a&gt; for inventory management at the beginning of the &lt;a href=\"Life-cycle%20assessment\"&gt;life cycle&lt;/a&gt; when a completely new product is being analyzed, the uniform distribution proves to be more useful. In this situation, other distribution may not be viable since there is no existing data on the new product or that the demand history is unavailable so there isn't really an appropriate or known distribution. The uniform distribution would be ideal in this situation since the random variable of lead-time (related to demand) is unknown for the new product but the results are likely to range between a plausible range of two values. The &lt;a href=\"Lead%20time\"&gt;lead-time&lt;/a&gt; would thus represent the random variable. From the uniform distribution model, other factors related to &lt;a href=\"Lead%20time\"&gt;lead-time&lt;/a&gt; were able to be calculated such as &lt;a href=\"cycle%20service%20level\"&gt;cycle service level&lt;/a&gt; and &lt;a href=\"shortage%20per%20cycle\"&gt;shortage per cycle&lt;/a&gt;. It was also noted that the uniform distribution was also used due to the simplicity of the calculations.\nSampling from an arbitrary distribution.\nThe uniform distribution is useful for sampling from arbitrary distributions. A general method is the inverse transform sampling method, which uses the &lt;a href=\"cumulative%20distribution%20function\"&gt;cumulative distribution function&lt;/a&gt; (CDF) of the target random variable. This method is very useful in theoretical work. Since simulations using this method require inverting the CDF of the target variable, alternative methods have been devised for the cases where the CDF is not known in closed form. One such method is &lt;a href=\"rejection%20sampling\"&gt;rejection sampling&lt;/a&gt;.\nThe &lt;a href=\"normal%20distribution\"&gt;normal distribution&lt;/a&gt; is an important example where the inverse transform method is not efficient. However, there is an exact method, the &lt;a href=\"Box%E2%80%93Muller%20transformation\"&gt;Box\u2013Muller transformation&lt;/a&gt;, which uses the inverse transform to convert two independent uniform &lt;a href=\"random%20variable\"&gt;random variable&lt;/a&gt;s into two independent &lt;a href=\"normal%20distribution\"&gt;normally distributed&lt;/a&gt; random variables.\nQuantization error.\nIn analog-to-digital conversion a quantization error occurs. This error is either due to rounding or truncation. When the original signal is much larger than one &lt;a href=\"least%20significant%20bit\"&gt;least significant bit (LSB)&lt;/a&gt;, the quantization error is not significantly correlated with the signal, and has an approximately uniform distribution. The &lt;a href=\"RMS%20error\"&gt;RMS error&lt;/a&gt; therefore follows from the variance of this distribution.\nComputational methods.\nSampling from a uniform distribution.\nThere are many applications in which it is useful to run simulation experiments. Many &lt;a href=\"programming%20language\"&gt;programming language&lt;/a&gt;s come with implementations to generate &lt;a href=\"Pseudorandom%20number%20sequence\"&gt;pseudo-random numbers&lt;/a&gt; which are effectively distributed according to the standard uniform distribution.\nIf \"u\" is a value sampled from the standard uniform distribution, then the value \"a\" + (\"b\" \u2212 \"a\")\"u\" follows the uniform distribution parametrised by \"a\" and \"b\", as described above.\nHistory.\nWhile the historical origins in the conception of uniform distribution are inconclusive, it is speculated that the term 'uniform' arose from the concept of &lt;a href=\"equiprobability\"&gt;equiprobability&lt;/a&gt; in dice games (note that the dice games would have &lt;a href=\"Discrete%20uniform%20distribution\"&gt;discrete&lt;/a&gt; and not continuous uniform sample space). &lt;a href=\"Equiprobability\"&gt;Equiprobability&lt;/a&gt; was mentioned in &lt;a href=\"Gerolamo%20Cardano\"&gt;Gerolamo Cardano's&lt;/a&gt; \"Liber de Ludo Aleae\", a manual written in 16th century and detailed on advanced probability calculus in relation to dice."
}