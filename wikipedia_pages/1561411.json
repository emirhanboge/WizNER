{
    "id": "1561411",
    "revid": "42935773",
    "url": "https://en.wikipedia.org/wiki?curid=1561411",
    "title": "Color balance",
    "text": "In &lt;a href=\"photography\"&gt;photography&lt;/a&gt; and &lt;a href=\"image%20processing\"&gt;image processing&lt;/a&gt;, color balance is the global adjustment of the intensities of the colors (typically red, green, and blue &lt;a href=\"primary%20colors\"&gt;primary colors&lt;/a&gt;). An important goal of this adjustment is to render specific colors \u2013 particularly neutral colors \u2013 correctly. Hence, the general method is sometimes called gray balance, neutral balance, or white balance. Color balance changes the overall mixture of colors in an image and is used for &lt;a href=\"color%20correction\"&gt;color correction&lt;/a&gt;. Generalized versions of color balance are used to correct colors other than neutrals or to deliberately change them for effect. The term white balance is called that way due to the nature of the adjustment in which colors are adjusted to make a white object (such as a piece of paper or a wall) appear white and not bluish or reddish. \nImage data acquired by sensors \u2013 either &lt;a href=\"photographic%20film\"&gt;film&lt;/a&gt; or electronic &lt;a href=\"image%20sensor\"&gt;image sensor&lt;/a&gt;s \u2013 must be transformed from the acquired values to new values that are appropriate for color reproduction or display. Several aspects of the acquisition and display process make such color correction essential \u2013 including that the acquisition sensors do not match the sensors in the human eye, that the properties of the display medium must be accounted for, and that the ambient viewing conditions of the acquisition differ from the display viewing conditions.\nThe color balance operations in popular &lt;a href=\"image%20editing\"&gt;image editing&lt;/a&gt; applications usually operate directly on the red, green, and blue channel &lt;a href=\"pixel\"&gt;pixel&lt;/a&gt; values, without respect to any color sensing or reproduction model. In film photography, color balance is typically achieved by using &lt;a href=\"color%20correction%20filter\"&gt;color correction filter&lt;/a&gt;s over the lights or on the camera lens.\nGeneralized color balance.\nSometimes the adjustment to keep neutrals neutral is called \"white balance\", and the phrase \"color balance\" refers to the adjustment that in addition makes other colors in a displayed image appear to have the same general appearance as the colors in an original scene. It is particularly important that neutral (gray, neutral, white) colors in a scene appear neutral in the reproduction.\nPsychological color balance.\nHumans relate to &lt;a href=\"Human%20skin%20color\"&gt;flesh tones&lt;/a&gt; more critically than other colors. Trees, grass and sky can all be off without concern, but if human flesh tones are 'off' then the human subject can look sick or dead. To address this critical color balance issue, the tri-color primaries themselves are formulated to \"not\" balance as a true neutral color. The purpose of this color primary imbalance is to more faithfully reproduce the flesh tones through the entire brightness range.\nIlluminant estimation and adaptation.\nMost digital cameras have means to select color correction based on the type of scene lighting, using either manual lighting selection, automatic white balance, or custom white balance. The algorithms for these processes perform generalized &lt;a href=\"chromatic%20adaptation\"&gt;chromatic adaptation&lt;/a&gt;.\nMany methods exist for color balancing. Setting a button on a camera is a way for the user to indicate to the processor the nature of the scene lighting. Another option on some cameras is a button which one may press when the camera is pointed at a &lt;a href=\"gray%20card\"&gt;gray card&lt;/a&gt; or other neutral colored object. This captures an image of the ambient light, which enables a digital camera to set the correct color balance for that light.\nThere is a large literature on how one might estimate the ambient lighting from the camera data and then use this information to transform the image data. A variety of algorithms have been proposed, and the quality of these has been debated. A few examples and examination of the references therein will lead the reader to many others. Examples are &lt;a href=\"Retinex\"&gt;Retinex&lt;/a&gt;, an &lt;a href=\"artificial%20neural%20network\"&gt;artificial neural network&lt;/a&gt; or a &lt;a href=\"Bayesian%20method\"&gt;Bayesian method&lt;/a&gt;.\nChromatic colors.\nColor balancing an image affects not only the neutrals, but other colors as well. An image that is not color balanced is said to have a color cast, as everything in the image appears to have been shifted towards one color. Color balancing may be thought in terms of removing this color cast.\nColor balance is also related to &lt;a href=\"color%20constancy\"&gt;color constancy&lt;/a&gt;. Algorithms and techniques used to attain color constancy are frequently used for color balancing, as well. Color constancy is, in turn, related to &lt;a href=\"chromatic%20adaptation\"&gt;chromatic adaptation&lt;/a&gt;. Conceptually, color balancing consists of two steps: first, determining the &lt;a href=\"standard%20illuminant\"&gt;illuminant&lt;/a&gt; under which an image was captured; and second, scaling the components (e.g., R, G, and B) of the image or otherwise transforming the components so they conform to the viewing illuminant.\nViggiano found that white balancing in the camera's native &lt;a href=\"RGB%20color%20model\"&gt;RGB color model&lt;/a&gt; tended to produce less color inconstancy (i.e., less distortion of the colors) than in monitor RGB for over 4000 hypothetical sets of camera sensitivities. This difference typically amounted to a factor of more than two in favor of camera RGB. This means that it is advantageous to get color balance right at the time an image is captured, rather than edit later on a monitor. If one must color balance later, balancing the &lt;a href=\"Raw%20image%20format\"&gt;raw image data&lt;/a&gt; will tend to produce less distortion of chromatic colors than balancing in monitor RGB.\nMathematics of color balance.\nColor balancing is sometimes performed on a three-component image (e.g., &lt;a href=\"RGB%20color%20model\"&gt;RGB&lt;/a&gt;) using a 3x3 &lt;a href=\"matrix%20%28mathematics%29\"&gt;matrix&lt;/a&gt;. This type of transformation is appropriate if the image was captured using the wrong white balance setting on a digital camera, or through a color filter.\nScaling monitor R, G, and B.\nIn principle, one wants to scale all relative luminances in an image so that objects which are believed to be &lt;a href=\"grey\"&gt;neutral&lt;/a&gt; appear so. If, say, a surface with formula_1 was believed to be a white object, and if 255 is the count which corresponds to white, one could multiply all &lt;a href=\"red\"&gt;red&lt;/a&gt; values by 255/240. Doing analogously for &lt;a href=\"green\"&gt;green&lt;/a&gt; and &lt;a href=\"blue\"&gt;blue&lt;/a&gt; would result, at least in theory, in a color balanced image. In this type of transformation the 3x3 matrix is a &lt;a href=\"diagonal%20matrix\"&gt;diagonal matrix&lt;/a&gt;.\nwhere formula_3, formula_4, and formula_5 are the color balanced red, green, and blue components of a &lt;a href=\"pixel\"&gt;pixel&lt;/a&gt; in the image; formula_6, formula_7, and formula_8 are the red, green, and blue components of the image before color balancing, and formula_9, formula_10, and formula_11 are the red, green, and blue components of a pixel which is believed to be a white surface in the image before color balancing. This is a simple scaling of the red, green, and blue channels, and is why color balance tools in &lt;a href=\"Photoshop\"&gt;Photoshop&lt;/a&gt; and the &lt;a href=\"GIMP\"&gt;GIMP&lt;/a&gt; have a white eyedropper tool. It has been demonstrated that performing the white balancing in the phosphor set assumed by &lt;a href=\"sRGB\"&gt;sRGB&lt;/a&gt; tends to produce large errors in chromatic colors, even though it can render the neutral surfaces perfectly neutral.\nScaling X, Y, Z.\nIf the image may be transformed into &lt;a href=\"CIE%201931%20color%20space\"&gt;CIE XYZ tristimulus values&lt;/a&gt;, the color balancing may be performed there. This has been termed a \u201cwrong von Kries\u201d transformation. Although it has been demonstrated to offer usually poorer results than balancing in monitor RGB, it is mentioned here as a bridge to other things. Mathematically, one computes:\nwhere formula_13, formula_14, and formula_15 are the color-balanced tristimulus values; formula_16, formula_17, and formula_18 are the tristimulus values of the viewing illuminant (the white point to which the image is being transformed to conform to); formula_19, formula_20, and formula_21 are the tristimulus values of an object believed to be white in the un-color-balanced image, and formula_22, formula_23, and formula_24 are the tristimulus values of a pixel in the un-color-balanced image. If the tristimulus values of the monitor primaries are in a matrix formula_25 so that:\nwhere formula_27, formula_28, and formula_29 are the un-&lt;a href=\"gamma%20correction\"&gt;gamma corrected&lt;/a&gt; monitor RGB, one may use:\nVon Kries's method.\n&lt;a href=\"Johannes%20von%20Kries\"&gt;Johannes von Kries&lt;/a&gt;, whose theory of &lt;a href=\"rod%20cell\"&gt;rods&lt;/a&gt; and three color-sensitive &lt;a href=\"cone%20cell\"&gt;cone&lt;/a&gt; types in the &lt;a href=\"retina\"&gt;retina&lt;/a&gt; has survived as the dominant explanation of color sensation for over 100 years, motivated the method of converting color to the &lt;a href=\"LMS%20color%20space\"&gt;LMS color space&lt;/a&gt;, representing the effective stimuli for the Long-, Medium-, and Short-wavelength cone types that are modeled as adapting independently. A 3x3 matrix converts RGB or XYZ to LMS, and then the three LMS primary values are scaled to balance the neutral; the color can then be converted back to the desired final &lt;a href=\"color%20space\"&gt;color space&lt;/a&gt;:\nwhere formula_32, formula_33, and formula_34 are the color-balanced LMS cone tristimulus values; formula_35, formula_36, and formula_37 are the tristimulus values of an object believed to be white in the un-color-balanced image, and formula_38, formula_39, and formula_40 are the tristimulus values of a pixel in the un-color-balanced image.\nMatrices to convert to LMS space were not specified by von Kries, but can be derived from CIE color matching functions and LMS color matching functions when the latter are specified; matrices can also be found in reference books.\nScaling camera RGB.\nBy Viggiano's measure, and using his model of gaussian camera spectral sensitivities, most camera RGB spaces performed better than either monitor RGB or XYZ. If the camera's raw RGB values are known, one may use the 3x3 diagonal matrix:\nand then convert to a working RGB space such as &lt;a href=\"sRGB\"&gt;sRGB&lt;/a&gt; or &lt;a href=\"Adobe%20RGB\"&gt;Adobe RGB&lt;/a&gt; after balancing.\nPreferred chromatic adaptation spaces.\nComparisons of images balanced by diagonal transforms in a number of different RGB spaces have identified several such spaces that work better than others, and better than camera or monitor spaces, for chromatic adaptation, as measured by several &lt;a href=\"color%20appearance%20model\"&gt;color appearance model&lt;/a&gt;s; the systems that performed statistically as well as the best on the majority of the image test sets used were the \"Sharp\", \"Bradford\", \"CMCCAT\", and \"ROMM\" spaces.\nGeneral illuminant adaptation.\nThe best color matrix for adapting to a change in illuminant is not necessarily a diagonal matrix in a fixed color space. It has long been known that if the space of illuminants can be described as a linear model with \"N\" basis terms, the proper color transformation will be the weighted sum of \"N\" fixed linear transformations, not necessarily consistently diagonalizable."
}