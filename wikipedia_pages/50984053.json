{
    "id": "50984053",
    "revid": "7126005",
    "url": "https://en.wikipedia.org/wiki?curid=50984053",
    "title": "Tesla Autopilot",
    "text": "Tesla Autopilot is a suite of &lt;a href=\"advanced%20driver-assistance%20systems\"&gt;advanced driver-assistance system&lt;/a&gt; (ADAS) features offered by &lt;a href=\"Tesla%2C%20Inc.\"&gt;Tesla&lt;/a&gt; that amounts to &lt;a href=\"Self-driving%20car%23Level%202\"&gt;Level 2&lt;/a&gt; vehicle automation. Its features are &lt;a href=\"lane%20centering\"&gt;lane centering&lt;/a&gt;, &lt;a href=\"adaptive%20cruise%20control\"&gt;traffic-aware cruise control&lt;/a&gt;, automatic lane changes, semi-autonomous navigation on limited access freeways, &lt;a href=\"self-parking\"&gt;self-parking&lt;/a&gt;, and the ability to summon the car from a garage or parking spot. In all of these features, the driver is responsible and the car requires constant supervision. The company claims the features reduce accidents caused by driver negligence and fatigue from long-term driving. In October 2020, &lt;a href=\"Consumer%20Reports\"&gt;Consumer Reports&lt;/a&gt; called Tesla Autopilot \"a distant second\" in driver assistance systems (behind &lt;a href=\"Cadillac\"&gt;Cadillac&lt;/a&gt;'s Super Cruise), although it was ranked first in the \"Capabilities and Performance\" and \"Ease of Use\" category.\nAs an upgrade to the base Autopilot capabilities, the company's stated intent is to offer &lt;a href=\"autonomous%20driving\"&gt;SAE Level 5&lt;/a&gt; (full autonomous driving) at a future time, acknowledging that regulatory and technical hurdles must be overcome to achieve this goal. As of April 2020, most experts believe that Tesla vehicles lack the necessary hardware for fully autonomous driving. In October 2020, Tesla initiated and commissioned customers for a Full Self-Driving &lt;a href=\"Software%20release%20life%20cycle%23Beta\"&gt;beta&lt;/a&gt; program in the United States; , it is being tested on public roads by 60,000 vehicles of employees and customers. Some industry observers criticized Tesla's decision to use untrained consumers to validate the beta software as dangerous and irresponsible. Similarly, collisions and deaths involving Tesla cars with Autopilot engaged have drawn the attention of the press and government agencies. In May 2021, Tesla was ranked last for both strategy and execution in the autonomous driving sector by &lt;a href=\"Navigant%20Consulting\"&gt;Guidehouse Insights&lt;/a&gt;. &lt;a href=\"Elon%20Musk\"&gt;Elon Musk&lt;/a&gt;, Tesla\u2019s CEO, has made inaccurate predictions for when Tesla would achieve SAE Level 5 for years.\nHistory.\n&lt;a href=\"Elon%20Musk\"&gt;Elon Musk&lt;/a&gt; first discussed the Tesla Autopilot system publicly in 2013, noting that \"Autopilot is a good thing to have in planes, and we should have it in cars.\" Over the ensuing decade, Autopilot went through a series of hardware and software enhancements, gradually approaching the goal of full autonomy, which as of January 2021, remained a work in progress.\nIn October 2014, Tesla offered customers the ability to pre-purchase Autopilot that was not designed for &lt;a href=\"Self-driving%20car\"&gt;self-driving&lt;/a&gt;. Initial versions were built in partnership with &lt;a href=\"Mobileye\"&gt;Mobileye&lt;/a&gt;, but Mobileye ended the partnership in July 2016 because Tesla \"was pushing the envelope in terms of safety\".\nTesla cars manufactured after September 2014 had the initial hardware (&lt;a href=\"%23Hardware%201\"&gt;hardware version 1&lt;/a&gt; or HW1) that supported Autopilot. The first Autopilot software release came in October 2015 as part of Tesla software version 7.0. Version 7.1 removed some features to discourage risky driving.\nVersion 8.0 processed radar signals to create a &lt;a href=\"point%20cloud\"&gt;point cloud&lt;/a&gt; similar to &lt;a href=\"lidar\"&gt;lidar&lt;/a&gt; to help navigate in low visibility. In November 2016, Autopilot 8.0 was updated to encourage drivers to grip the steering wheel. By November 2016, Autopilot had operated for 300 million miles (500\u00a0million km).\nIn October 2016, Autopilot sensors and computing hardware transitioned to &lt;a href=\"%23Hardware%202\"&gt;hardware version 2&lt;/a&gt; (HW2). Tesla used the term Enhanced Autopilot (EA) to refer to novel HW2 capabilities. In February 2017 Autopilot gained the ability to navigate freeways, to change lanes without driver input, to transition from one freeway to another, and to exit the freeway. It included traffic-aware cruise control, &lt;a href=\"Lane%20centering\"&gt;autosteer&lt;/a&gt; on divided highways, and autosteer on 'local roads' up to a speed of 45\u00a0mph. Software version 8.1 for HW2 arrived in March 2017, providing HW2 cars software parity with HW1 cars. The following August, Tesla announced &lt;a href=\"%23Hardware%202.5\"&gt;hardware version 2.5&lt;/a&gt; (HW2.5).\nIn March 2019, Tesla transitioned again, to &lt;a href=\"%23Hardware%203\"&gt;hardware version 3&lt;/a&gt; (HW3). To comply with the new &lt;a href=\"United%20Nations%20Economic%20Commission%20for%20Europe\"&gt;United Nations Economic Commission for Europe&lt;/a&gt; regulation related to &lt;a href=\"Lane%20centering\"&gt;automatically commanded steering function&lt;/a&gt;, Tesla provided an updated Autopilot in May limited to Europe. In September, Tesla released software version 10 to Early Access Program (EAP) testers, citing improvements in driving visualization and automatic lane changes.\nIn September 2020, Tesla reintroduced the term Enhanced Autopilot to designate the subset of features applying to highway travel, parking, and summoning, whereas the Full-Self Driving option included navigation on city roads. Tesla released a \"&lt;a href=\"Software%20release%20life%20cycle%23Beta\"&gt;beta&lt;/a&gt;\" version of its Full Self-Driving software in the United States in October 2020 to EAP testers.\nPricing.\nThe initial price of basic Autopilot as of 2016, was $5,000. Full Self-Driving (FSD) was an additional $3,000. Later basic Autopilot was included in every Tesla and the additional FSD was $8,000 growing to $10,000 in 2021 and $12,000 in 2022. The company offered a monthly subscription for FSD in 2021, at a price of $200 per month. As the price increased, the fraction of owners who purchased it steadily declined, to 12% in 2021, down from 22% in 2020 and 37% in 2019.\nExecutive turnover.\nThere has been reportedly high turnover in the role for leading the Autopilot team, with as many as five executives holding the position in a 4-year period.\nStarting in 2018, the executives are:\nFull Self-Driving.\nFull Self-Driving (FSD) is an upgrade package to Autopilot offering additional ADAS features. , the beta FSD software is available to employees, early access program members, and more than ten thousand opt-in users who met certain safety score criteria.\nApproach.\nTesla's approach to try to achieve SAE Level 5 is to train a &lt;a href=\"Neural%20network%20software\"&gt;neural network&lt;/a&gt; using the behavior of hundreds of thousands of Tesla drivers using chiefly &lt;a href=\"visible%20light\"&gt;visible light&lt;/a&gt; cameras and information from components used for other purposes in the car (the coarse-grained two-dimensional maps used for navigation; the ultrasonic sensors used for parking, etc.) Tesla has made a deliberate decision to not use &lt;a href=\"lidar\"&gt;lidar&lt;/a&gt;, which Elon Musk has called \"stupid, expensive and unnecessary\". This makes Tesla's approach markedly different from that of other companies like &lt;a href=\"Waymo\"&gt;Waymo&lt;/a&gt; and &lt;a href=\"Cruise%20%28autonomous%20vehicle%29\"&gt;Cruise&lt;/a&gt; which train their neural networks using the behavior of highly trained drivers, and are additionally relying on highly detailed (centimeter-scale) three-dimensional maps and lidar in their autonomous vehicles.\nAccording to Elon Musk, full autonomy is \"really a software limitation: The hardware exists to create full autonomy, so it's really about developing advanced, &lt;a href=\"narrow%20AI\"&gt;narrow AI&lt;/a&gt; for the car to operate on.\" The Autopilot development focus is on \"increasingly sophisticated &lt;a href=\"Artificial%20neural%20network\"&gt;neural nets&lt;/a&gt; that can operate in reasonably sized computers in the car\". According to Musk, \"the car will learn over time\", including from other cars.\nTesla's software has been trained based on 3\u00a0billion miles driven by Tesla vehicles on public roads, . Alongside tens of millions of miles on public roads, competitors have trained their software on tens of billions of miles in computer simulations, as of January 2020. In terms of computing hardware, Tesla designed a self-driving computer chip that has been installed in its cars since March 2019 and also developed a &lt;a href=\"Neural%20network%20software\"&gt;neural network&lt;/a&gt; training supercomputer; other vehicle automation companies such as Waymo regularly use custom chipsets and neural networks as well.\nCriticism.\nTesla's self-driving strategy has been criticized as dangerous and obsolete as it was abandoned by other companies years ago. Most experts believe that Tesla's approach of trying to achieve autonomous vehicles by eschewing high-definition maps and lidar is not feasible. Auto analyst &lt;a href=\"Brad%20Templeton\"&gt;Brad Templeton&lt;/a&gt; has criticized Tesla's approach by arguing, \"The no-map approach involves forgetting what was learned before and doing it all again.\" In a May 2021 study by Guidehouse Insights, Tesla was ranked last for both strategy and execution in the autonomous driving sector. Some news reports in 2019 state \"practically everyone views [lidar] as an essential ingredient for self-driving cars\" and \"experts and proponents say it adds depth and vision where camera and radar alone fall short.\"\nAn August 2021 study conducted by &lt;a href=\"Missy%20Cummings\"&gt;Missy Cummings&lt;/a&gt; et al found three Tesla Model 3 cars exhibited \"significant between and within vehicle variation on a number of metrics related to driver monitoring, alerting, and safe operation of the underlying autonomy... suggest[ing] that the performance of the underlying artificial intelligence and computer vision systems was extremely variable.\"\nIn July 2020, German authorities ruled that Tesla misled consumers regarding the \"abilities of its automated driving systems\" and banned it from using certain marketing language implying autonomous driving capabilities.\nIn September 2021, legal scholars William Widen and Philip Koopman argued that Tesla has misrepresented FSD as &lt;a href=\"Self-driving%20car%23Level%202\"&gt;SAE Level 2&lt;/a&gt; to \"avoid regulatory oversight and permitting processes required of more highly automated vehicles\". Instead, they argued FSD should be considered a SAE Level 4 technology and urged state Departments of Transportation in the U.S. to classify it as such since publicly available videos show that \"beta test drivers operate their vehicles \"as if\" to validate SAE Level 4 (high driving automation) features, often revealing dramatically risky situations created by use of the vehicles in this manner.\"\nPredictions and deployment.\nIn March 2015, speaking at an &lt;a href=\"Nvidia\"&gt;Nvidia&lt;/a&gt; conference, Musk stated:\nIn December 2015, Musk predicted \"complete autonomy\" by 2018. At the end of 2016, Tesla expected to demonstrate full autonomy by the end of 2017, and in April 2017, Musk predicted that in around two years, drivers would be able to sleep in their vehicle while it drives itself. In 2018 Tesla revised the date to demonstrate full autonomy to be by the end of 2019.\nIn February 2019, Musk stated that Tesla's FSD capability would be \"&lt;a href=\"feature%20complete\"&gt;feature complete&lt;/a&gt;\" by the end of 2019:\nIn January 2020, Musk claimed the FSD software would be \"feature complete\" by the end of 2020, adding that feature complete \"doesn't mean that features are working well\". In August 2020, Musk stated that 200 software engineers, 100 hardware engineers and 500 \"&lt;a href=\"Labeled%20data\"&gt;labelers&lt;/a&gt;\" were working on Autopilot and FSD. In early 2021, Musk stated that Tesla would provide &lt;a href=\"Self-driving%20car%23Levels%20of%20driving%20automation\"&gt;SAE Level 5 autonomy&lt;/a&gt; by the end of 2021 and that Tesla plans to release a monthly subscription package for FSD in 2021. An email conversation between Tesla and the &lt;a href=\"California%20Department%20of%20Motor%20Vehicles\"&gt;California Department of Motor Vehicles&lt;/a&gt; retrieved via a &lt;a href=\"Freedom%20of%20Information%20Act%20%28United%20States%29\"&gt;Freedom of Information Act&lt;/a&gt; request by &lt;a href=\"PlainSite\"&gt;PlainSite&lt;/a&gt; contradicts Musk's forward-looking statement.\nFull Self-Driving beta.\nIn October 2020, Tesla released a beta version of its FSD software to EAP testers, a small group of users in the United States. Musk stated that the testing of FSD beta \"[w]ill be extremely slow [and] cautious\" and \"be limited to a small number of people who are expert &amp; careful drivers\". The release of the beta program has renewed concern regarding whether the technology is ready for testing on public roads. In January 2021, the number of employees and customers testing the beta FSD software was \"nearly 1,000\" and in May 2021 a couple thousand employees and customers. In October 2021, Tesla started the wide release of the FSD Beta to about 1,000 more drivers in the US. The beta became accessible to Tesla drivers who achieved a 100 / 100 on a proprietary safety scoring system.\nAs of November 2021 there were about 11,700 FSD beta testers and about 150,000 vehicles using Tesla's safety score system. , there are 60,000 users participating in FSD beta.\nTesla Dojo.\nTesla Dojo (or Project Dojo) is an &lt;a href=\"artificial%20intelligence\"&gt;artificial intelligence&lt;/a&gt; (AI) &lt;a href=\"neural%20network\"&gt;neural network&lt;/a&gt; training &lt;a href=\"supercomputer\"&gt;supercomputer&lt;/a&gt; announced by Musk on Tesla's AI Day on August 19, 2021. It had previously been mentioned by Musk in April 2019 and August 2020. According to Musk, Project Dojo will be operational in 2022.\nThe Dojo supercomputer will use Tesla D1 chips, designed and produced by Tesla. According to Tesla's senior director of Autopilot hardware, Ganesh Venkataramanan, the chip uses a \"&lt;a href=\"7%20nm%20process\"&gt;7-nanometer manufacturing process&lt;/a&gt;, with 362 &lt;a href=\"teraflop\"&gt;teraflop&lt;/a&gt;s of processing power\", and \"Tesla places 25 of these chips onto a single 'training tile', and 120 of these tiles come together... amounting to over an &lt;a href=\"exaflop\"&gt;exaflop&lt;/a&gt; [a million teraflops] of power\". Tesla claims that Dojo will be the fastest AI-training computer among competing offerings from &lt;a href=\"Intel\"&gt;Intel&lt;/a&gt; and &lt;a href=\"Nvidia\"&gt;Nvidia&lt;/a&gt;. , Nvidia says the current Tesla AI-training center uses 720 nodes of eight &lt;a href=\"Ampere%20%28microarchitecture%29\"&gt;Nvidia A100&lt;/a&gt; Tensor Core GPUs (5,760 GPUs in total) for up to 1.8 exaflops of performance.\n&lt;a href=\"Gartner\"&gt;Gartner&lt;/a&gt; research vice president Chirag Dekate said, \"The Tesla Dojo is an AI-specific supercomputer designed to accelerate machine learning and deep learning activities. Its lower precision focus limits applicability to a broader &lt;a href=\"Supercomputer\"&gt;high-performance computer&lt;/a&gt; (HPC) context.\" He also said that Dojo's reported capabilities don't grant it true HPC status, largely because it hasn't been tested using the same standards as &lt;a href=\"Fugaku%20%28supercomputer%29\"&gt;Fugaku&lt;/a&gt; and other supercomputers. Dylan Patel from Semi Analysis suggests that while the &lt;a href=\"I/O\"&gt;input/output&lt;/a&gt; is impressive, the amount of memory is inadequate, and the two most difficult issues (the software compiler and tile-to-tile interconnects) remain to be solved.\nIn September 2021, Tesla Dojo whitepaper was released.\nDriving features.\nTesla's Autopilot is classified as Level 2 under the &lt;a href=\"SAE%20International\"&gt;SAE International&lt;/a&gt; &lt;a href=\"Self-driving%20car%23SAE%20classification\"&gt;six levels (0 to 5) of vehicle automation&lt;/a&gt;. At this level, the car can act autonomously, but requires the driver to monitor the driving at all times and be prepared to take control at a moment's notice. Tesla's owner's manual states that Autopilot should not be used on city streets or on roads where traffic conditions are constantly changing; however, some current FSD capabilities (\"traffic and stop sign control (beta)\"), and future FSD capabilities (\"autosteer on city streets\") are advertised for city streets.\nHardware.\nHardware 1.\nVehicles manufactured after late September 2014 are equipped with a camera mounted at the top of the windshield, forward looking &lt;a href=\"radar\"&gt;radar&lt;/a&gt; in the lower grille and ultrasonic &lt;a href=\"acoustic%20location\"&gt;acoustic location&lt;/a&gt; sensors in the front and rear bumpers that provide a 360-degree view around the car. The computer is the Mobileye EyeQ3. This equipment allows the &lt;a href=\"Tesla%20Model%20S\"&gt;Tesla Model S&lt;/a&gt; to detect road signs, lane markings, obstacles, and other vehicles.\nAuto lane change can be initiated by the driver turning on the lane changing signal when safe (due to ultrasonic 16-foot limited range capability), and then the system completes the lane change. In 2016 the HW1 did not detect pedestrians or cyclists, and while Autopilot detects motorcycles, there have been two instances of HW1 cars &lt;a href=\"rear-end%20collision\"&gt;rear-ending&lt;/a&gt; motorcycles.\nUpgrading from Hardware 1 to Hardware 2 is not offered as it would require substantial work and cost.\nHardware 2.\nHW2, included in all vehicles manufactured after October 2016, includes an &lt;a href=\"Nvidia\"&gt;Nvidia&lt;/a&gt; &lt;a href=\"Drive%20PX-series%23Drive%20PX%202\"&gt;Drive PX 2&lt;/a&gt; GPU for &lt;a href=\"CUDA\"&gt;CUDA&lt;/a&gt; based &lt;a href=\"GPGPU\"&gt;GPGPU&lt;/a&gt; computation. Tesla claimed that HW2 provided the necessary equipment to allow FSD capability at &lt;a href=\"SAE%20International\"&gt;SAE&lt;/a&gt; Level 5. The hardware includes eight surround cameras and 12 ultrasonic sensors, in addition to forward-facing radar with enhanced processing capabilities. The Autopilot computer is replaceable to allow for future upgrades. The radar is able to observe beneath and ahead of the vehicle in front of the Tesla; the radar can see vehicles through heavy rain, fog or dust. Tesla claimed that the hardware was capable of processing 200 frames per second.\nWhen \"Enhanced Autopilot\" was enabled in February 2017 by the v8.0 (17.5.36) software update, testing showed the system was limited to using one of the eight onboard cameras\u2014the main forward-facing camera. The v8.1 software update released a month later enabled a second camera, the narrow-angle forward-facing camera.\nHardware 2.5.\nIn August 2017, Tesla announced that HW2.5 included a secondary processor node to provide more computing power and additional wiring redundancy to slightly improve reliability; it also enabled dashcam and sentry mode capabilities.\nHardware 3.\nAccording to Tesla's director of Artificial Intelligence &lt;a href=\"Andrej%20Karpathy\"&gt;Andrej Karpathy&lt;/a&gt;, Tesla had as of Q3 2018 trained large neural networks that work but which could not be deployed to Tesla vehicles built up to that time due to their insufficient computational resources. HW3 provides the necessary resources to run these neural networks.\nHW3 includes a custom Tesla-designed &lt;a href=\"system%20on%20a%20chip\"&gt;system on a chip&lt;/a&gt; fabricated using &lt;a href=\"14%20nm%20process\"&gt;14 nm process&lt;/a&gt; by Samsung. &lt;a href=\"Jim%20Keller%20%28engineer%29\"&gt;Jim Keller&lt;/a&gt; and Pete Bannon among other architects have led the project since February 2016 and took over the course of 18 months. Tesla claimed that the new system processes 2,300 frames per second (fps), which is a 21\u00d7 improvement over the 110 fps image processing capability of HW2.5. The firm described it as a \"neural network accelerator\". Each chip is capable of 36\u00a0trillion operations per second, and there are two chips for redundancy. The company claimed that HW3 was necessary for FSD, but not for \"enhanced Autopilot\" functions.\nThe first availability of HW3 was April 2019. Customers with HW2 or HW2.5 who purchased the FSD package are eligible for an upgrade to HW3 without cost.\nTesla claims HW3 has 2.5\u00d7 improved performance over HW2.5 with 1.25\u00d7 higher power and 0.2\u00d7 lower cost. HW3 features twelve &lt;a href=\"ARM%20Cortex-A72\"&gt;ARM Cortex-A72&lt;/a&gt; CPUs operating at 2.6\u00a0GHz, two Neural Network Accelerators operating at 2\u00a0GHz and a &lt;a href=\"Mali%20%28GPU%29\"&gt;Mali GPU&lt;/a&gt; operating at 1\u00a0GHz.\nTesla Vision.\nIn late May 2021, Elon Musk posted to Twitter that \"Pure Vision Autopilot\" was starting to be implemented. The system, which Tesla brands \"Tesla Vision\", eliminates the forward-facing radar from the Autopilot hardware package on Model 3 and Model Y vehicles built for the North American market and delivered in and after May 2021. For vehicles without the forward radar, temporary limitations were applied to certain features such as Autosteer, and other features (Smart Summon and Emergency Lane Departure Avoidance) were disabled, but Tesla promised to restore the features \"in the weeks ahead ... via a series of over-the-air software updates\". In response, the U.S. &lt;a href=\"National%20Highway%20Traffic%20Safety%20Administration\"&gt;National Highway Traffic Safety Administration&lt;/a&gt; (NHTSA) rescinded the agency's check marks for forward collision warning, automatic emergency braking, lane departure warning, and dynamic brake support, applicable to Model 3 and Model Y vehicles built on or after April 27, 2021. \"Consumer Reports\" delisted the Model 3 from its Top Picks, and the &lt;a href=\"Insurance%20Institute%20for%20Highway%20Safety\"&gt;Insurance Institute for Highway Safety&lt;/a&gt; (IIHS) announced plans to delist the Model 3 as a Top Safety Pick+, but after further testing, both organizations restored those designations.\nIn December 2021, the \"New York Times\" reported that Musk was the decisionmaker behind the camera-only approach and had \"repeatedly told members of the Autopilot team that humans could drive with only two eyes and that this meant cars should be able to drive with cameras alone.\" Several autonomous vehicle experts were quoted denouncing the analogy.\nSafety concerns.\nThe &lt;a href=\"National%20Transportation%20Safety%20Board\"&gt;National Transportation Safety Board&lt;/a&gt; (NTSB) criticized Tesla's lack of system safeguards in a fatal 2018 Autopilot crash in California, and for failing to foresee and prevent \"predictable abuse\" of Autopilot. The &lt;a href=\"Center%20for%20Auto%20Safety\"&gt;Center for Auto Safety&lt;/a&gt; and &lt;a href=\"Consumer%20Watchdog\"&gt;Consumer Watchdog&lt;/a&gt; called for federal and state investigations into Autopilot and Tesla's marketing of the technology, which they believe is \"dangerously misleading and deceptive\", giving consumers the false impression that their vehicles are self-driving or autonomous. UK safety experts called Tesla's Autopilot \"especially misleading\". A 2019 IIHS study showed that the name \"Autopilot\" causes more drivers to misperceive behaviors such as texting or taking a nap to be safe, versus similar level 2 driver-assistance systems from other car companies. Tesla's Autopilot and FSD features were criticized in a May 2020 report published on &lt;a href=\"ScienceDirect\"&gt;ScienceDirect&lt;/a&gt; titled \"Autonowashing: The Greenwashing of Vehicle Automation\".\nIn June 2021, the NHTSA announced an order requiring automakers to report crashes involving vehicles equipped with ADAS features in the United States. This order came amid increased regulatory scrutiny of such systems, especially Tesla Autopilot. An MIT study published in September 2021 found that Autopilot is not as safe as Tesla claims, and led to drivers becoming inattentive.\nDriver monitoring.\nDrivers have been found sleeping at the wheel, driving under the influence of alcohol, and doing other inappropriate tasks with Autopilot engaged. Initially, Tesla decided against using driver monitoring options to limit such activities. It was not until late May 2021 that a new version of the OTA software turned on inside cameras for new Model 3 and Model Y (i.e. the first cars as part of the switch to Tesla Vision) to monitor drivers using Autopilot. Model S and Model X cars made before 2021 do not have an inside camera and therefore physically cannot offer such capabilities, although the refreshed versions are expected to have one. A review of the in-cabin camera-based monitoring system by Consumer Reports found that drivers could still use Autopilot even when looking away from the road or using their phones, and could also enable FSD beta software \"with the camera covered.\"\nDetecting stationary vehicles at speed.\nAutopilot may not detect stationary vehicles; the manual states: \"Traffic-Aware Cruise Control cannot detect all objects and may not brake/decelerate for stationary vehicles, especially in situations when you are driving over and a vehicle you are following moves out of your driving path and a stationary vehicle or object is in front of you instead.\" This has led to numerous crashes with stopped emergency vehicles. This is the same problem that any car equipped with just adaptive cruise control or automated emergency braking has (for example, Volvo Pilot Assist).\nDangerous and unexpected behavior.\nIn a 2019 Bloomberg survey, hundreds of Tesla owners reported dangerous behaviors with Autopilot, such as phantom braking, veering out of lane, or failing to stop for road hazards. Autopilot users have also reported the software crashing and turning off suddenly, collisions with off ramp barriers, radar failures, unexpected swerving, tailgating, and uneven speed changes.\n&lt;a href=\"Ars%20Technica\"&gt;Ars Technica&lt;/a&gt; notes that the brake system tends to initiate later than some drivers expect. One driver claimed that Tesla's Autopilot failed to brake, resulting in collisions, but Tesla pointed out that the driver deactivated the cruise control of the car prior to the crash. Ars Technica also notes that while &lt;a href=\"lane\"&gt;lane&lt;/a&gt; changes may be semi-automatic (if Autopilot is on, and the vehicle detects slow moving cars or if it is required to stay on route, the car may automatically change lanes without any driver input), the driver must show the car that he or she is paying attention by touching the steering wheel before the car makes the change. In 2019, \"Consumer Reports\" found that Tesla's automatic lane-change feature is \"far less competent than a human driver\".\nIn October 2021, version 10.3 of the \"Full Self-Driving\" beta software was released with different driving profiles to control vehicle behavior, branded 'Chill', 'Average', and 'Assertive'; the 'Assertive' profile attracted negative coverage in January 2022 for advertising that it \"may perform &lt;a href=\"rolling%20stop\"&gt;rolling stop&lt;/a&gt;s\". On February 1, after the NHTSA advised Tesla that failing to stop for a stop sign can increase the risk of a crash, Tesla recalled nearly 54,000 vehicles to disable the rolling stop behavior. The recall will be implemented through software.\nRegulation.\nA spokesman for the NHTSA said that \"any autonomous vehicle would need to meet applicable federal motor vehicle safety standards\" and the NHTSA \"will have the appropriate policies and regulations in place to ensure the safety of this type of vehicles\". On February 1, 2021, &lt;a href=\"Robert%20L.%20Sumwalt%20%28U.S.%20government%20official%29\"&gt;Robert Sumwalt&lt;/a&gt;, chair of the NTSB, wrote a letter to NHTSA regarding that agency's \"Framework for Automated Driving System Safety\", which had been published for comment in December 2020. In the letter, Sumwalt recommended that NHTSA include user monitoring as part of the safety framework and reiterated that \"Tesla's lack of appropriate safeguards and NHTSA's inaction\" to act on the NTSB's recommendation \"that NHTSA develop a method to verify that manufacturers of vehicles equipped with Level 2 incorporate system safeguards that limit the use of automated vehicle control systems to the conditions for which they were designed\" was a contributing cause to a fatal crash of a vehicle in Delray Beach, Florida.\nNHTSA announced Standing General Order 2021-01 on June 29, 2021. Under this General Order, manufacturers and operators of vehicles equipped with advanced driver assistance systems (ADAS, SAE J3016 Level 2) or automated driving systems (ADS, SAE Level 3 or higher) are required to report crashes. An amended order was issued and became effective on August 12. Reporting is limited to crashes where the ADAS or ADS was engaged within 30 seconds prior to the crash that involve a injury that requires hospitalization, a fatality, a vehicle being towed from the scene, an air bag deployment, or involving a \"vulnerable road user\" (e.g., pedestrian or bicyclist); these crashes are required to be reported to NHTSA within one calendar day, and an updated report is required within 10 calendar days.\nCourt cases.\nTesla's Autopilot was the subject of a &lt;a href=\"class%20action%20suit\"&gt;class action suit&lt;/a&gt; brought in 2017 that claimed the second-generation Enhanced Autopilot system was \"dangerously defective\". The suit was settled in 2018; owners who had paid in 2016 and 2017 to equip their cars with the updated Autopilot software were compensated between $20 and $280 for the delay in implementing Autopilot 2.0.\nIn July 2020, a German court ruled that Tesla made exaggerated promises about its Autopilot technology, and that the \"Autopilot\" name created the false impression that the car can drive itself.\nOn August 16, 2021, after reports of 17 injuries and one death in car crashes involving emergency vehicles, the US auto safety regulators opened a formal safety probe into Tesla's driver assistance system Autopilot.\nSafety statistics.\nIn 2016, data after 47 million miles of driving in Autopilot mode showed the probability of an accident was at least 50% lower when using Autopilot. During the investigation into the fatal crash of May 2016 in Williston, Florida, NHTSA released a preliminary report in January 2017 stating \"the Tesla vehicles' crash rate dropped by almost 40 percent after Autosteer installation.\" Disputing this, in 2019, a private company, Quality Control Systems, released their report analyzing the same data, stating the NHTSA conclusion was \"not well-founded\". Quality Control Systems' analysis of the data showed the crash rate (measured in the rate of airbag deployments per million miles of travel) actually increased from 0.76 to 1.21 after the installation of Autosteer.\nIn February 2020, Andrej Karpathy, Tesla's head of AI and computer vision, stated that: Tesla cars have driven 3 billion miles on Autopilot, of which 1 billion have been driven using Navigate on Autopilot; Tesla cars have performed 200,000 automated lane changes; and 1.2 million Smart Summon sessions have been initiated with Tesla cars. He also stated that Tesla cars are avoiding pedestrian accidents at a rate of tens to hundreds per day.\nNHTSA investigations.\nAccording to a document released in June 2021, the NHTSA has initiated at least 30 investigations into Tesla crashes that were believed to involve the use of Autopilot, with some involving fatalities.\nIn August 2021, the NHTSA Office of Defects Investigation (ODI) opened a preliminary evaluation (PE 21-020) and released a list of eleven crashes involving Tesla vehicles striking emergency vehicles; in each instance, NHTSA confirmed that Autopilot or Traffic Aware Cruise Control were active during the approach to the crashes. Of the eleven crashes, seven resulted in seventeen injuries, and one resulted in one fatality. NHTSA planned to evaluate the Autopilot system, specifically the systems used to monitor and enforce driver engagement. In September, NHTSA added a twelfth accident to the investigation list.\nNHTSA sent a request for information relating to PE 21-020 to Tesla's director of field quality on August 31, 2021. The response was due by October 22. On September 13, NHTSA sent a request for information to other automobile manufacturers for comparative ADAS data. After Tesla deployed its Emergency Light Detection Update in September 2021, NHTSA sent a follow-up letter to Tesla was on October 12 asking for \"a chronology of events, internal investigations, and studies\" that led to the deployment of the update.\nNotable crashes.\nFatal crashes.\nAs of January 2022, there have been twelve verified fatalities involving Tesla's Autopilot, though other deadly incidents where Autopilot use was suspected remain outstanding.\nHandan, Hebei, China (January 20, 2016).\nOn January 20, 2016, the driver of a Tesla Model S in &lt;a href=\"Handan\"&gt;Handan&lt;/a&gt;, Hebei, China, was killed when his car crashed into a stationary truck. The Tesla was following a car in the far left lane of a multi-lane highway; the car in front moved to the right lane to avoid a truck stopped on the left shoulder, and the Tesla, which the driver's father believes was in Autopilot mode, did not slow before colliding with the stopped truck. According to footage captured by a &lt;a href=\"dashboard%20camera\"&gt;dashboard camera&lt;/a&gt;, the stationary street sweeper on the left side of the expressway partially extended into the far left lane, and the driver did not appear to respond to the unexpected obstacle.\nIn September 2016, the media reported the driver's family had filed a lawsuit in July against the Tesla dealer who sold the car. The family's lawyer stated the suit was intended \"to let the public know that self-driving technology has some defects. We are hoping Tesla when marketing its products, will be more cautious. Do not just use self-driving as a selling point for young people.\" Tesla released a statement which said they \"have no way of knowing whether or not Autopilot was engaged at the time of the crash\" since the car &lt;a href=\"telemetry\"&gt;telemetry&lt;/a&gt; could not be retrieved remotely due to damage caused by the crash. In 2018, the lawsuit was stalled because telemetry was recorded locally to a &lt;a href=\"Secure%20Digital\"&gt;SD card&lt;/a&gt; and was not able to be given to Tesla, who provided a decoding key to a third party for independent review. Tesla stated that \"while the third-party appraisal is not yet complete, we have no reason to believe that Autopilot on this vehicle ever functioned other than as designed.\" Chinese media later reported that the family sent the information from that card to Tesla, which admitted autopilot was engaged two minutes before the crash. Tesla since then removed the term \"Autopilot\" from its Chinese website.\nWilliston, Florida, USA (May 7, 2016).\nOn May 7, 2016, a Tesla driver was killed in a crash with an 18-wheel &lt;a href=\"tractor-trailer\"&gt;tractor-trailer&lt;/a&gt; in &lt;a href=\"Williston%2C%20Florida\"&gt;Williston, Florida&lt;/a&gt;. By late June 2016, the NHTSA opened a formal investigation into the fatal autonomous accident, working with the &lt;a href=\"Florida%20Highway%20Patrol\"&gt;Florida Highway Patrol&lt;/a&gt;. According to the NHTSA, preliminary reports indicate the crash occurred when the tractor-trailer made a left turn in front of the 2015 Tesla Model S at an intersection on a non-controlled access highway, and the car failed to apply the brakes. The car continued to travel after passing under the truck's trailer. The Tesla was eastbound in the rightmost lane of &lt;a href=\"U.S.%20Route%2027%20in%20Florida\"&gt;US 27&lt;/a&gt;, and the westbound tractor-trailer was turning left at the intersection with NE 140th Court, approximately west of Williston; the posted speed limit is .\nThe diagnostic log of the Tesla indicated it was traveling at a speed of when it collided with and traveled under the trailer, which was not equipped with a &lt;a href=\"Semi-trailer%20truck%23Underride%20guard\"&gt;side underrun protection system&lt;/a&gt;. A reconstruction of the accident estimated the driver would have had approximately 10.4\u00a0seconds to detect the truck and take evasive action. The underride collision sheared off the Tesla's glasshouse, destroying everything above the &lt;a href=\"Beltline%20%28automotive%29\"&gt;beltline&lt;/a&gt;, and caused fatal injuries to the driver. In the approximately nine seconds after colliding with the trailer, the Tesla traveled another and came to rest after colliding with two chain-link fences and a utility pole.\nThe NHTSA's preliminary evaluation was opened to examine the design and performance of any automated driving systems in use at the time of the crash, which involves a population of an estimated 25,000 Model S cars. On July 8, 2016, the NHTSA requested Tesla Inc. to hand over to the agency detailed information about the design, operation and testing of its Autopilot technology. The agency also requested details of all design changes and updates to Autopilot since its introduction, and Tesla's planned updates scheduled for the next four months.\nAccording to Tesla, \"neither autopilot nor the driver noticed the white side of the tractor-trailer against a brightly lit sky, so the brake was not applied.\" The car attempted to drive full speed under the trailer, \"with the bottom of the trailer impacting the windshield of the Model S\". Tesla also stated that this was Tesla's first known Autopilot-related death in over 130 million miles (208\u00a0million km) driven by its customers while Autopilot was activated. According to Tesla there is a fatality every 94\u00a0million miles (150\u00a0million km) among all type of vehicles in the U.S. It is estimated that billions of miles will need to be traveled before Tesla Autopilot can claim to be safer than humans with statistical significance. Researchers say that Tesla and others need to release more data on the limitations and performance of automated driving systems if self-driving cars are to become safe and understood enough for mass-market use.\nThe truck's driver told the &lt;a href=\"Associated%20Press\"&gt;Associated Press&lt;/a&gt; that he could hear a &lt;a href=\"Harry%20Potter%20%28film%20series%29\"&gt;\"Harry Potter\" movie&lt;/a&gt; playing in the crashed car, and said the car was driving so quickly that \"he went so fast through my trailer I didn't see him. [The film] was still playing when he died and snapped a telephone pole a quarter-mile down the road.\" According to the Florida Highway Patrol, they found in the wreckage an aftermarket &lt;a href=\"portable%20DVD%20player\"&gt;portable DVD player&lt;/a&gt;. It is not possible to watch videos on the Model S &lt;a href=\"touchscreen\"&gt;touchscreen&lt;/a&gt; display. A laptop computer was recovered during the post-crash examination of the wreck, along with an &lt;a href=\"Docking%20station%23Mobile%20docking%20stations\"&gt;adjustable vehicle laptop mount&lt;/a&gt; attached to the front passenger's seat frame. The NHTSA concluded the laptop was probably mounted and the driver may have been distracted at the time of the crash.\nIn January 2017, the NHTSA Office of Defects Investigations (ODI) released a preliminary evaluation, finding that the driver in the crash had seven seconds to see the truck and identifying no defects in the Autopilot system; the ODI also found that the Tesla car crash rate dropped by 40 percent after Autosteer installation, but later also clarified that it did not assess the effectiveness of this technology or whether it was engaged in its crash rate comparison. The NHTSA Special Crash Investigation team published its report in January 2018. According to the report, for the drive leading up to the crash, the driver engaged Autopilot for 37 minutes and 26 seconds, and the system provided 13 \"hands not detected\" alerts, to which the driver responded after an average delay of 16 seconds. The report concluded \"Regardless of the operational status of the Tesla's ADAS technologies, the driver was still responsible for maintaining ultimate control of the vehicle. All evidence and data gathered concluded that the driver neglected to maintain complete control of the Tesla leading up to the crash.\"\nIn July 2016, the NTSB announced it had opened a formal investigation into the fatal accident while Autopilot was engaged. The NTSB is an investigative body that only has the power to make policy recommendations. An agency spokesman said, \"It's worth taking a look and seeing what we can learn from that event, so that as that automation is more widely introduced we can do it in the safest way possible.\" The NTSB opens annually about 25 to 30 highway investigations. In September 2017, the NTSB released its report, determining that \"the probable cause of the Williston, Florida, crash was the truck driver's failure to yield the right of way to the car, combined with the car driver's inattention due to overreliance on vehicle automation, which resulted in the car driver's lack of reaction to the presence of the truck. Contributing to the car driver's overreliance on the vehicle automation was its operational design, which permitted his prolonged disengagement from the driving task and his use of the automation in ways inconsistent with guidance and warnings from the manufacturer.\"\nMountain View, California, USA (March 23, 2018).\nOn March 23, 2018, a second U.S. Autopilot fatality occurred in &lt;a href=\"Mountain%20View%2C%20California\"&gt;Mountain View, California&lt;/a&gt;. The crash occurred just before 9:30\u00a0A.M. on southbound &lt;a href=\"Bayshore%20Freeway\"&gt;US 101&lt;/a&gt; at the carpool lane exit for southbound &lt;a href=\"California%20State%20Route%2085\"&gt;Highway 85&lt;/a&gt;, at a concrete barrier where the left-hand carpool lane offramp separates from 101. After the Model X crashed into the narrow concrete barrier, it was struck by two following vehicles, and then it caught on fire.\nBoth the NHTSA and NTSB began investigations into the March 2018 crash. Another driver of a Model S demonstrated that Autopilot appeared to be confused by the &lt;a href=\"road%20surface%20marking\"&gt;road surface marking&lt;/a&gt; in April 2018. The &lt;a href=\"Gore%20%28road%29\"&gt;gore&lt;/a&gt; ahead of the barrier is marked by diverging solid white lines (a vee-shape) and the Autosteer feature of the Model S appeared to mistakenly use the left-side white line instead of the right-side white line as the lane marking for the far left lane, which would have led the Model S into the same concrete barrier had the driver not taken control. \"Ars Technica\" concluded that \"as Autopilot gets better, drivers could become increasingly complacent and pay less and less attention to the road.\"\nIn a corporate blog post, Tesla noted the impact attenuator separating the offramp from US 101 had been previously crushed and not replaced prior to the Model X crash on March 23. The post also stated that Autopilot was engaged at the time of the crash, and the driver's hands had not been detected manipulating the steering wheel for six seconds before the crash. Vehicle data showed the driver had five seconds and a \"unobstructed view of the concrete divider, ... but the vehicle logs show that no action was taken.\" The NTSB investigation had been focused on the damaged &lt;a href=\"impact%20attenuator\"&gt;impact attenuator&lt;/a&gt; and the vehicle fire after the collision, but after it was reported the driver had complained about the Autopilot functionality, the NTSB announced it would also investigate \"all aspects of this crash including the driver's previous concerns about the autopilot\". A NTSB spokesman stated the organization \"is unhappy with the release of investigative information by Tesla\". Elon Musk dismissed the criticism, tweeting that NTSB was \"an advisory body\" and that \"Tesla releases critical crash data affecting public safety immediately &amp; always will. To do otherwise would be unsafe.\" In response, NTSB removed Tesla as a party to the investigation on April 11.\nNTSB released a preliminary report on June 7, 2018, which provided the recorded telemetry of the Model X and other factual details. Autopilot was engaged continuously for almost nineteen minutes prior to the crash. In the minute before the crash, the driver's hands were detected on the steering wheel for 34 seconds in total, but his hands were not detected for the six seconds immediately preceding the crash. Seven seconds before the crash, the Tesla began to steer to the left and was following a lead vehicle; four seconds before the crash, the Tesla was no longer following a lead vehicle; and during the three seconds before the crash, the Tesla's speed increased to . The driver was wearing a seatbelt and was pulled from the vehicle before it was engulfed in flames.\nThe crash attenuator had been previously damaged on March 12 and had not been replaced at the time of the Tesla crash. The driver involved in the accident on March 12 collided with the crash attenuator at more than and was treated for minor injuries; in comparison, the driver of the Tesla collided with the collapsed attenuator at a slower speed and died from blunt force trauma. After the accident on March 12, the &lt;a href=\"California%20Highway%20Patrol\"&gt;California Highway Patrol&lt;/a&gt; failed to report the collapsed attenuator to Caltrans as required. Caltrans was not aware of the damage until March 20, and the attenuator was not replaced until March 26 because a spare was not immediately available. This specific attenuator had required repair more often than any other crash attenuator in the Bay Area, and maintenance records indicated that repair of this attenuator was delayed by up to three months after being damaged. As a result, the NTSB released a Safety Recommendation Report on September 9, 2019, asking &lt;a href=\"California%20Department%20of%20Transportation\"&gt;Caltrans&lt;/a&gt; to develop and implement a plan to guarantee timely repair of traffic safety hardware.\nAt a NTSB meeting held on February 25, 2020, the board concluded the crash was caused by a combination of the limitations of the Tesla Autopilot system, the driver's over-reliance on Autopilot, and driver distraction likely from playing a video game on his phone. The vehicle's ineffective monitoring of driver engagement was cited as a contributing factor, and the inoperability of the crash attenuator contributed to the driver's injuries. As an advisory agency, NTSB does not have regulatory power; however, NTSB made several recommendations to two regulatory agencies. The NTSB recommendations to the NHTSA included: expanding the scope of the &lt;a href=\"New%20Car%20Assessment%20Program\"&gt;New Car Assessment Program&lt;/a&gt; to include testing of forward collision avoidance systems; determining if \"the ability to operate [Tesla Autopilot-equipped vehicles] outside the intended operational design domain pose[s] an unreasonable risk to safety\"; and developing driver monitoring system performance standards. The NTSB submitted recommendations to the OSHA relating to &lt;a href=\"distracted%20driving\"&gt;distracted driving&lt;/a&gt; awareness and regulation. In addition, NTSB issued recommendations to manufacturers of portable electronic devices (to develop lock-out mechanisms to prevent driver-distracting functions) and to &lt;a href=\"Apple%20Inc.\"&gt;Apple&lt;/a&gt; (banning the nonemergency use of portable electronic devices while driving).\nSeveral NTSB recommendations previously issued to NHTSA, DOT, and Tesla were reclassified to \"Open\u2014Unacceptable Response\". These included H-17-41 (recommendation to Tesla to incorporate system safeguards that limit the use of automated vehicle control systems to design conditions) and H-17-42 (recommendation to Tesla to more effectively sense the driver's level of engagement).\nKanagawa, Japan (April 29, 2018).\nOn April 29, 2018, a Tesla Model X operating on Autopilot struck and killed a pedestrian in Kanagawa, Japan, after the driver had fallen asleep. According to a lawsuit filed against Tesla in &lt;a href=\"United%20States%20District%20Court%20for%20the%20Northern%20District%20of%20California\"&gt;federal court (N.D. Cal.)&lt;/a&gt; in April 2020, the Tesla Model X accelerated from after the vehicle in front of it changed lanes; it then crashed into a van, motorcycles, and pedestrians in the far right lane of the expressway, killing a 44-year-old man on the road directing traffic. The original complaint claims the accident occurred due to flaws in Tesla's Autopilot system, such as inadequate monitoring to detect inattentive drivers and an inability to handle traffic situations \"that drivers will almost always certainly encounter\". In addition, the original complaint claimed this is the first pedestrian fatality to result from the use of Autopilot.\nAccording to vehicle data logs, the driver of the Tesla had engaged autopilot at 2:11\u00a0pm (local time), shortly after entering the &lt;a href=\"T%C5%8Dmei%20Expressway\"&gt;T\u014dmei Expressway&lt;/a&gt;. The driver's hands were detected on the wheel at 2:22\u00a0pm. At some point before 2:49\u00a0pm, the driver began to doze off, and at approximately 2:49\u00a0pm, the vehicle ahead of the Tesla signaled and moved one lane to the left to avoid the vehicles stopped in the far right lane of the expressway. While the Tesla was accelerating to resume its preset speed, it struck the man, killing him. He belonged to a motorcycle riding club which had stopped to render aid to a friend that had been involved in an earlier accident; he specifically had been standing apart from the main group while trying to redirect traffic away from that earlier accident.\nThe driver of the Tesla was convicted in a Japanese court of criminal negligence and sentenced to three years in prison (suspended for five years). The suit against Tesla in California was dismissed for \"&lt;a href=\"forum%20non-conveniens\"&gt;forum non-conveniens&lt;/a&gt;\" by Judge &lt;a href=\"Susan%20van%20Keulen\"&gt;Susan van Keulen&lt;/a&gt; in September 2020 after Tesla said it would accept a case brought in Japan. The plaintiffs appealed the dismissal to the &lt;a href=\"United%20States%20Court%20of%20Appeals%20for%20the%20Ninth%20Circuit\"&gt;Ninth Circuit Court of Appeals&lt;/a&gt; in February 2021.\nDelray Beach, Florida, USA (March 1, 2019).\nAt approximately 6:17\u00a0am on the morning of March 1, 2019, a Tesla Model 3 driving southbound on &lt;a href=\"U.S.%20Route%20441\"&gt;US 441&lt;/a&gt;/&lt;a href=\"Florida%20State%20Road%207\"&gt;SR 7&lt;/a&gt; in &lt;a href=\"Delray%20Beach%2C%20Florida\"&gt;Delray Beach, Florida&lt;/a&gt; struck a &lt;a href=\"semi-trailer%20truck\"&gt;semi-trailer truck&lt;/a&gt; that was making a left-hand turn to northbound SR 7 out of a private driveway at Pero Family Farms; the Tesla &lt;a href=\"Semi-trailer%20truck%23Underride%20guard\"&gt;underrode&lt;/a&gt; the trailer, and the force of the impact sheared off the greenhouse of the Model 3, resulting in the death of the Tesla driver. The driver of the Tesla had engaged Autopilot approximately 10 seconds before the collision and preliminary telemetry showed the vehicle did not detect the driver's hands on the wheel for the eight seconds immediately preceding the collision. The driver of the semi-trailer truck was not cited. Both the NHTSA and NTSB dispatched investigators to the scene.\nAccording to telemetry recorded by the Tesla's restraint control module, the Tesla's cruise control was set to 12.3 seconds prior to the collision and Autopilot was engaged 9.9 seconds prior to the collision; at the moment of impact, the vehicle speed was . After the crash and underride, the Tesla continued southbound on SR\u00a07 for approximately before coming to rest in the median between the northbound and southbound lanes. The car sustained extensive damage to the roof, windshield, and other surfaces above , the clearance under the trailer. Although the airbags did not deploy following the collision, the Tesla's driver remained restrained by his seatbelt; emergency response personnel were able to determine the driver's injuries were incompatible with life upon arriving at the scene.\nIn May 2019 the NTSB issued a preliminary report that determined that neither the driver of the Tesla or the Autopilot system executed evasive maneuvers. The circumstances of this crash were similar to the fatal underride crash of a Tesla Model S in 2016 near Williston, Florida; in its 2017 report detailing the investigation of that earlier crash, NTSB recommended that Autopilot be used only on limited-access roads (i.e., freeway), which Tesla did not implement.\nThe NTSB issued its final report in March 2020. The probable cause of the collision was the truck driver's failure to yield the right of way to the Tesla; however, the report also concluded that \"an attentive car driver would have seen the truck in time to take evasive action. At no time before the crash did the car driver brake or initiate an evasive steering action. In addition, no driver-applied steering wheel torque was detected for 7.7 seconds before impact, indicating driver disengagement, likely due to overreliance on the Autopilot system.\" In addition, the NTSB concluded the operational design of the Tesla Autopilot system \"permitted disengagement by the driver\" and Tesla failed to \"limit the use of the system to the conditions for which it was designed\"; the NHTSA also failed to develop a method of verifying that manufacturers had safeguards in place to limit the use of ADAS to design conditions.\nKey Largo, Florida, USA (April 25, 2019).\nWhile driving on &lt;a href=\"County%20Road%20905A%20%28Monroe%20County%2C%20Florida%29\"&gt;Card Sound Road&lt;/a&gt;, a 2019 Model S ran through a stop sign and flashing red stop light at the T-intersection with &lt;a href=\"County%20Road%20905%20%28Monroe%20County%2C%20Florida%29\"&gt;County Road 905&lt;/a&gt;, then struck a parked Chevrolet Tahoe which then hit two pedestrians, killing one. A &lt;a href=\"The%20New%20York%20Times\"&gt;\"New York Times\"&lt;/a&gt; article later confirmed Autopilot was engaged at the time of the accident. The driver of the Tesla, who was commuting to his home in Key Largo from his office in Boca Raton, told police at the scene that he was driving in \"cruise\"; he was allowed to leave without receiving a citation.\nFremont, California, USA (August 24, 2019).\nIn &lt;a href=\"Fremont%2C%20California\"&gt;Fremont, California&lt;/a&gt; on &lt;a href=\"Interstate%20880%20in%20California\"&gt;I-880&lt;/a&gt;, while driving north of Stevenson Boulevard, a Ford Explorer pickup was rear-ended by a Tesla Model 3 using Autopilot, causing the pickup's driver to lose control. The pickup overturned and a 15-year-old passenger in the Ford, who was not seat-belted, was jettisoned from the pickup and killed. The deceased's parents sued Tesla and claimed in their filing that \"Autopilot contains defects and failed to react to traffic conditions.\" In response, a lawyer for Tesla noted the police had cited the driver of the Tesla for inattention and operating the car at an unsafe speed. The incident has not been investigated by the NHTSA.\nCloverdale, Indiana, USA (December 29, 2019).\nAn eastbound Tesla Model 3 rear-ended a fire truck parked along &lt;a href=\"Interstate%2070%20in%20Indiana\"&gt;I-70&lt;/a&gt; near mile marker 38 in &lt;a href=\"Putnam%20County%2C%20Indiana\"&gt;Putnam County, Indiana&lt;/a&gt; at approximately 8\u00a0am; both the driver and passenger in the Tesla, a married couple, were injured and taken to &lt;a href=\"Terre%20Haute%20Regional%20Hospital\"&gt;Terre Haute Regional Hospital&lt;/a&gt;, where the passenger later died from her injuries. The driver stated he regularly uses Autopilot mode, but could not recall if it was engaged when the Tesla hit the fire truck. The NHTSA announced it was investigating the crash on January 9 and later confirmed the use of Autopilot at the time of the crash.\nGardena, California, USA (December 29, 2019).\nShortly before 12:39\u00a0a.m. on December 29, 2019, a westbound Tesla Model S exited the freeway section of &lt;a href=\"California%20State%20Route%2091\"&gt;SR 91&lt;/a&gt;, failed to stop for a red light, and crashed into the driver's side of Honda Civic in Gardena, California, killing the driver and passenger in the Civic and injuring the Tesla driver and passenger. The freeway section of SR\u00a091 ends just east of the intersection of &lt;a href=\"Artesia%20Boulevard\"&gt;Artesia Blvd&lt;/a&gt; and &lt;a href=\"Vermont%20Avenue\"&gt;Vermont Ave&lt;/a&gt;, and continues as Artesia. The Tesla was proceeding west on Artesia against the red light when it struck the Civic, which was turning left from Vermont onto Artesia. The occupants of the Tesla were taken to the hospital with non life-threatening injuries.\nThe NHTSA initiated an investigation of the crash, which was considered unusual for a two-vehicle collision, and later confirmed in January 2022 that Autopilot was engaged during the crash. The Tesla driver was charged in October 2021 with vehicular manslaughter in the &lt;a href=\"Los%20Angeles%20Superior%20Court\"&gt;Los Angeles Superior Court&lt;/a&gt;. The families of the two killed also have filed separate civil lawsuits against the driver, for his negligence, and Tesla, for selling defective vehicles.\nArendal, Norway (May 29, 2020).\nA truck driver parked a semi-trailer on May 29, 2020, partially off &lt;a href=\"European%20route%20E18\"&gt;E18&lt;/a&gt; near the Torsbu\u00e5s tunnel outside &lt;a href=\"Arendal\"&gt;Arendal&lt;/a&gt;; while fixing a strap that was securing the load, he was struck and killed by a passing Tesla. The Tesla's driver has been charged with negligent homicide. Early in the trial, an expert witness testified that the car's computer indicates Autopilot was engaged at the time of the incident. A forensic scientist said the killed man was less visible because he was in the shadow of the trailer. The driver said he had both hands on the wheel, and that he was vigilant. , the &lt;a href=\"Accident%20Investigation%20Board%20Norway\"&gt;Accident Investigation Board Norway&lt;/a&gt; is still investigating.\nThe Woodlands, Texas, USA (April 17, 2021).\nA Tesla Model S &lt;a href=\"Tesla%20Model%20S%23Specifications\"&gt;P100D&lt;/a&gt; crashed and caught fire in &lt;a href=\"The%20Woodlands%2C%20Texas\"&gt;The Woodlands, Texas&lt;/a&gt;, a suburb of &lt;a href=\"Houston\"&gt;Houston&lt;/a&gt;, at 11:25\u00a0pm &lt;a href=\"Central%20Daylight%20Time\"&gt;CDT&lt;/a&gt; on April 17, 2021. According to a police spokesperson, the vehicle was traveling at a high speed and after failing to negotiate a curve, departed the roadway, crashed into a tree, and burst into flames; the resulting fire took four hours and more than of water to extinguish. Two men were killed; one was found in the front passenger seat, and the other was in the back seat. The chief of The Woodlands fire department later clarified the fire had been extinguished within a few minutes of arriving on the scene, but could not perform final extinguishment due to the bodies and it being an investigation/crime scene, so a steady stream of water was required to keep the battery cool. Investigators from both NHTSA and NTSB have been dispatched to investigate.\nThe post-crash fire destroyed the car's onboard telemetry storage; although the restraint control module/event data recorder (EDR) was damaged by the fire, it is being evaluated at the NTSB's recorder laboratory. Based on data recovered from the EDR, the vehicle traveled approximately westbound on Hammock Dunes Place from the owner's residence before it departed the roadway. After leaving the road and driving over the &lt;a href=\"Curb%23Shape\"&gt;mountable curb&lt;/a&gt;, the car hit a drainage culvert, raised manhole, and tree. The highest recorded speed in the five seconds leading up to the crash was . Security footage from the point of departure at the owner's residence showed that when the car left, one man was in the driver's seat, and the other was in the front passenger seat.\nBecause neither man was found behind the wheel of the Tesla, authorities initially were \"100 percent certain that no one was in the driver seat driving that vehicle at the time of impact\". Authorities also obtained statements from witnesses who said the two men wanted to test drive the vehicle without a driver. On a closed course, \"&lt;a href=\"Consumer%20Reports\"&gt;Consumer Reports&lt;/a&gt;\" demonstrated that Autopilot would stay engaged after a person climbed out of the driver's seat by using a weight to apply torque to the steering wheel and leaving the driver's seatbelt buckled.\nHowever, a more detailed forensic investigation showed the driver's seat was likely occupied at the time of the crash, and that Autopilot was not engaged. In response to early assertions that Autopilot was involved, Elon Musk stated on Twitter that data logs indicated that Autopilot was not enabled, and the FSD package had not been purchased for that car. During an &lt;a href=\"earnings%20call\"&gt;earnings call&lt;/a&gt; in April 2021, Tesla's vice president of vehicle engineering pushed back on the news coverage of the incident and added that Tesla representatives had studied the crash and reported the steering wheel was \"deformed\", which could indicate \"someone was in the driver's seat at the time of the crash\". The same Tesla officer noted a test car's &lt;a href=\"adaptive%20cruise%20control\"&gt;adaptive cruise control&lt;/a&gt; had accelerated the car to only at the crash site. The NTSB tested an exemplar car at the site and found that Autosteer was not available on that part of Hammock Dunes. In an update published on October 21, the NTSB concluded that both the driver and front passenger seats were occupied at the time of the crash, based on the deformation of the steering wheel and data recovered from the car's event data recorder.\nFontana, California, USA (May 5, 2021).\nAt 2:35 A.M. &lt;a href=\"Pacific%20Daylight%20Time\"&gt;PDT&lt;/a&gt; on May 5, 2021, a Tesla Model 3 crashed into an overturned tractor-trailer on the westbound &lt;a href=\"Foothill%20Freeway\"&gt;Foothill Freeway&lt;/a&gt; (I-210) in &lt;a href=\"Fontana%2C%20California\"&gt;Fontana, California&lt;/a&gt;. The driver of the Tesla was killed, and a man who had stopped to assist the driver of the truck was struck and injured by the Tesla. &lt;a href=\"California%20Highway%20Patrol\"&gt;California Highway Patrol&lt;/a&gt; (CHP) officials announced on May 13 that Autopilot \"was engaged\" prior to the crash, but added a day later that \"a final determination [has not been] made as to what driving mode the Tesla was in or if it was a contributing factor to the crash\". The CHP and NHTSA are investigating the crash.\nQueens, New York, USA (July 26, 2021).\nWhile his vehicle was parked on the left shoulder of the westbound &lt;a href=\"Long%20Island%20Expressway\"&gt;Long Island Expressway&lt;/a&gt;, just east of the College Point Boulevard exit in &lt;a href=\"Flushing%2C%20Queens\"&gt;Flushing, Queens&lt;/a&gt;, as he was changing a flat tire, a man was hit and killed by a Tesla Model Y SUV. The NHTSA later determined Autopilot was active during the collision and sent a team to further investigate.\nNon-fatal crashes.\nCulver City, California, USA (January 22, 2018).\nOn January 22, 2018, a 2014 Tesla Model S crashed into a fire truck parked on the side of the &lt;a href=\"Interstate%20405%20%28California%29\"&gt;I-405&lt;/a&gt; freeway in &lt;a href=\"Culver%20City%2C%20California\"&gt;Culver City, California&lt;/a&gt;, while traveling at a speed exceeding and the driver survived with no injuries. The driver told the Culver City Fire Department that he was using Autopilot. The fire truck and a California Highway Patrol vehicle were parked diagonally across the left emergency lane and high-occupancy vehicle lane of the southbound 405, blocking off the scene of an earlier accident, with emergency lights flashing.\nAccording to a post-accident interview, the driver stated he was drinking coffee, eating a bagel, and maintaining contact with the steering wheel while resting his hand on his knee. During the trip, which lasted 66 minutes, the Autopilot system was engaged for slightly more than 29 minutes; of the 29 minutes, hands were detected on the steering wheel for only 78 seconds in total. Hands were detected applying torque to the steering wheel for only 51 seconds over the nearly 14 minutes immediately preceding the crash. The Tesla had been following a lead vehicle in the high-occupancy vehicle lane at approximately ; when the lead vehicle moved to the right to avoid the fire truck, approximately three or four seconds prior to impact, the Tesla's traffic-aware cruise control system began to accelerate the Tesla to its preset speed of . When the impact occurred, the Tesla had accelerated to . The Autopilot system issued a forward collision warning half a second before the impact, but did not engage the automatic emergency braking (AEB) system, and the driver did not manually intervene by braking or steering. Because Autopilot requires agreement between the radar and visual cameras to initiate AEB, the system was challenged due to the specific scenario (where a lead vehicle detours around a stationary object) and the limited time available after the forward collision warning.\nSeveral news outlets started reporting that Autopilot may not detect stationary vehicles at highway speeds and it cannot detect some objects. Raj Rajkumar, who studies autonomous driving systems at &lt;a href=\"Carnegie%20Mellon%20University\"&gt;Carnegie Mellon University&lt;/a&gt;, believes the radars used for Autopilot are designed to detect moving objects, but are \"not very good in detecting stationary objects\". Both NTSB and NHTSA dispatched teams to investigate the crash. &lt;a href=\"Hod%20Lipson\"&gt;Hod Lipson&lt;/a&gt;, director of &lt;a href=\"Columbia%20University\"&gt;Columbia University&lt;/a&gt;'s Creative Machines Lab, faulted the &lt;a href=\"diffusion%20of%20responsibility\"&gt;diffusion of responsibility&lt;/a&gt; concept: \"If you give the same responsibility to two people, they each will feel safe to drop the ball. Nobody has to be 100%, and that's a dangerous thing.\"\nIn August 2019, the NTSB released its accident brief for the accident. HAB-19-07 concluded the driver of the Tesla was at fault due to \"inattention and overreliance on the vehicle's advanced driver assistance system\", but added the design of the Tesla Autopilot system \"permitted the driver to disengage from the driving task\". After the earlier crash in Williston, the NTSB issued a safety recommendation to \"[d]evelop applications to more effectively sense the driver's level of engagement and alert the driver when engagement is lacking while automated vehicle control systems are in use.\" Among the manufacturers that the recommendation was issued to, only Tesla has failed to issue a response.\nSouth Jordan, Utah, USA (May 11, 2018).\nIn the evening of May 11, 2018, a 2016 Tesla Model S with Autopilot engaged crashed into the rear of a &lt;a href=\"fire%20truck\"&gt;fire truck&lt;/a&gt; that was stopped in the southbound lane at a red light in &lt;a href=\"South%20Jordan%2C%20Utah\"&gt;South Jordan, Utah&lt;/a&gt;, at the intersection of &lt;a href=\"Utah%20State%20Route%20154\"&gt;SR-154&lt;/a&gt; and &lt;a href=\"Utah%20State%20Route%20151\"&gt;SR-151&lt;/a&gt;. The Tesla was moving at an estimated and did not appear to brake or attempt to avoid the impact, according to witnesses. The driver of the Tesla, who survived the impact with a broken foot, admitted she was looking at her phone before the crash. The NHTSA dispatched investigators to South Jordan. According to telemetry data recovered after the crash, the driver repeatedly did not touch the wheel, including during the 80 seconds immediately preceding the crash, and only touched the brake pedal \"fractions of a second\" before the crash. The driver was cited by police for \"failure to keep proper lookout\". The Tesla had slowed to to match a vehicle ahead of it, and after that vehicle changed lanes, accelerated to in the 3.5 seconds preceding the crash.\nTesla CEO Elon Musk criticized news coverage of the South Jordan crash, tweeting that \"a Tesla crash resulting in a broken ankle is front page news and the ~40,000 people who died in US auto accidents alone in [the] past year get almost no coverage\", additionally pointing out that \"[a]n impact at that speed usually results in severe injury or death\", but later conceding that Autopilot \"certainly needs to be better &amp; we work to improve it every day\". In September 2018, the driver of the Tesla sued the manufacturer, alleging the safety features designed to \"ensure the vehicle would stop on its own in the event of an obstacle being present in the path ... failed to engage as advertised.\" According to the driver, the Tesla failed to provide an audible or visual warning before the crash.\nMoscow, Russia (August 10, 2019).\nOn the night of August 10, 2019, a Tesla Model 3 driving in the left-hand lane on the &lt;a href=\"Moscow%20Ring%20Road\"&gt;Moscow Ring Road&lt;/a&gt; in Moscow, Russia crashed into a parked tow truck with a corner protruding into the lane and subsequently burst into flames. According to the driver, the vehicle was traveling at the speed limit of with Autopilot activated; he also claimed his hands were on the wheel, but was not paying attention at the time of the crash. All occupants were able to exit the vehicle before it caught on fire; they were transported to the hospital. Injuries included a broken leg (driver) and bruises (his children).\nThe force of the collision was enough to push the tow truck forward into the central dividing wall, as recorded by a surveillance camera. Passersby also captured several videos of the fire and explosions after the accident, these videos also show the tow truck that the Tesla crashed into had been moved, suggesting the explosions of the Model 3 happened later.\nChiayi, Taiwan (June 1, 2020).\nTraffic cameras captured the moment when a Tesla Model 3 slammed into an overturned cargo truck in Taiwan on June 1, 2020. The crash occurred at 6:40\u00a0am &lt;a href=\"Time%20in%20Taiwan\"&gt;National Standard Time&lt;/a&gt; on the southbound &lt;a href=\"National%20Freeway%201\"&gt;National Freeway 1&lt;/a&gt; in &lt;a href=\"Chiayi\"&gt;Chiayi&lt;/a&gt;, Taiwan, at approximately the south 268.4\u00a0km marker. The truck had been involved in a traffic accident at 6:35\u00a0am and overturned with its roof facing oncoming traffic; the driver of the truck got out to warn other cars away.\nThe driver of the Tesla was uninjured and told emergency responders that the car was in Autopilot mode, traveling at . The driver told authorities that he saw the truck and thought the Tesla would brake automatically upon encountering an obstacle; when he realized it would not, he manually applied the brakes, although it was too late to avoid the crash, which is apparently indicated on the video by a puff of white smoke coming from the tires.\nArlington Heights, Washington, USA (May 15, 2021).\nA Tesla Model S crashed into a stopped &lt;a href=\"Snohomish%20County%2C%20Washington\"&gt;Snohomish County, Washington&lt;/a&gt; sheriff's patrol car at 6:40\u00a0pm &lt;a href=\"Pacific%20Daylight%20Time\"&gt;PDT&lt;/a&gt; on May 15, 2021, shortly after the deputy parked it while responding to an earlier crash which had broken a utility pole near the intersection of &lt;a href=\"Washington%20State%20Route%20530\"&gt;SR 530&lt;/a&gt; and 103rd Ave NE in &lt;a href=\"Arlington%20Heights%2C%20Washington\"&gt;Arlington Heights, Washington&lt;/a&gt;. The patrol car was parked to partially block the roadway and protect the collision scene, and the patrol car's &lt;a href=\"emergency%20vehicle%20lighting\"&gt;overhead emergency lights&lt;/a&gt; were activated. Neither the deputy nor the driver of the Tesla were injured. The driver of the Tesla assumed his car would slow and move over on its own because it was in \"Auto-Pilot mode\".\nBrea, California, USA (November 3, 2021)\nIn November 2021, the NHTSA received its first complaint regarding a Tesla participating in FSD Beta. The incident was described as a \"severe\" crash involving a Tesla Model Y forcing itself into the incorrect lane."
}