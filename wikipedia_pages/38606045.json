{
    "id": "38606045",
    "revid": "10434788",
    "url": "https://en.wikipedia.org/wiki?curid=38606045",
    "title": "WikiArt",
    "text": "WikiArt (formerly known as WikiPaintings) is an online, user-editable visual art &lt;a href=\"encyclopedia\"&gt;encyclopedia&lt;/a&gt;. Based upon a statement in its 2013 financial report, the site appears to have been online since 2010.\nCurrent Development.\nIn January 2020, the site shows the following numbers:\nThe developers are based in &lt;a href=\"Ukraine\"&gt;Ukraine&lt;/a&gt;. Since 2010, the Editor in Chief of WikiArt is Ukrainian art critic Kseniia Bilash.\nSince 2016, WikiArt features female artists' pages. According to the statement on the site, it \"... advocates for better representation of &lt;a href=\"women%20artists\"&gt;women artists&lt;/a&gt;. It addresses the gender imbalance in the presentation of art by bringing to light important women artists of the past and promoting great women artists working today. It is designed to bring recognition to the achievements of women artists of all periods and nationalities, distinguishing them within the male-dominated art world.\"\nSince 2019, WikiArt has presented a Short Films section, curated by &lt;a href=\"London\"&gt;London&lt;/a&gt; based award-winning director Dekel Berenson.\nCopyright Policy.\nWikiArt contains both public domain and copyright protected artworks. Works not in the public domain are presented in accordance with fair use principle.\nWikiArt and AI Research.\nBecause of its availability to public, and a considerable database combined with well-developed structure, WikiArt is often used by scientists who study &lt;a href=\"Artificial%20intelligence\"&gt;AI&lt;/a&gt;. Namely, they train AI on WikiArt data trying to discover its ability to recognize, classify, and generate art.\n2015, Computer scientists Babak Saleh and Ahmed Egammal of &lt;a href=\"Rutgers%20University\"&gt;Rutgers University&lt;/a&gt;, used the images from WikiArt in training an algorithm to look at paintings and detect the works\u2019 genre, style and artist. Later, researchers from Rutgers University, the &lt;a href=\"College%20of%20Charleston\"&gt;College of Charleston&lt;/a&gt; and Facebook's AI Lab collaborated on GAN (&lt;a href=\"generative%20adversarial%20network\"&gt;generative adversarial network&lt;/a&gt;s), training it on WikiArt data to tell the difference between a piece of art versus a photograph or diagram, and to identify different styles of art. Then, they designed CAN (&lt;a href=\"creative%20adversarial%20networks\"&gt;creative adversarial networks&lt;/a&gt;), also trained on WikiArt dataset, to generate new works that does not fit known artistic styles.\n2016, Chee Seng Chan (Associate Professor at &lt;a href=\"University%20of%20Malaya\"&gt;University of Malaya&lt;/a&gt;) and his co-researchers trained CNN (&lt;a href=\"convolutional%20neural%20network\"&gt;convolutional neural network&lt;/a&gt;s) on WikiArt datasets and presented their paper \u201cCeci n\u2019est pas une pipe: A Deep Convolutional Network for Fine-art Paintings Classification\u201d. They released ArtGAN to explore the possibilities of AI in its relation to art.\n2017, new study and Improved ArtGAN was published: \"Improved ArtGAN for Conditional Synthesis of Natural Image and Artwork\".\n2018, \"&lt;a href=\"Edmond%20de%20Belamy\"&gt;Edmond de Belamy&lt;/a&gt;\" portrait produced by GAN was sold for $432,500 at &lt;a href=\"Christie%27s\"&gt;Christie's&lt;/a&gt; auction. The algorithm was trained on a set of 15,000 portraits from WikiArt, spanning the 14th to the 19th century.\n2019, Eva Cetinic, researcher at the &lt;a href=\"Ru%C4%91er%20Bo%C5%A1kovi%C4%87%20Institute\"&gt;Rudjer Boskovic Institute&lt;/a&gt; in Croatia, and her colleagues used images from WikiArt in training machine-learning algorithms to explore the relationship between the aesthetics, sentimental value, and memorability of fine art.\n2020, Panos Achlioptas, a researcher at &lt;a href=\"Stanford%20University\"&gt;Stanford University&lt;/a&gt; and his co-researchers collected 439,121 affective annotations involving emotional reactions and written explanations of those, for 81K artworks of WikiArt. Their study involved 6,377 human annotators and it resulted in the first neural-based speaker model that showed non-trivial &lt;a href=\"Turing%20test\"&gt;Turing test&lt;/a&gt; performance, in emotion-explanation tasks."
}