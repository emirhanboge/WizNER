{
    "id": "357366",
    "revid": "43270027",
    "url": "https://en.wikipedia.org/wiki?curid=357366",
    "title": "Heuristic evaluation",
    "text": "A heuristic evaluation is a &lt;a href=\"usability%20inspection\"&gt;usability inspection&lt;/a&gt; method for computer software that helps to identify &lt;a href=\"usability\"&gt;usability&lt;/a&gt; problems in the &lt;a href=\"User%20Interface%20Design\"&gt;user interface (UI) design&lt;/a&gt;. It specifically involves evaluators examining the interface and judging its compliance with recognized usability principles (the \"heuristics\"). These evaluation methods are now widely taught and practiced in the &lt;a href=\"new%20media\"&gt;new media&lt;/a&gt; sector, where UIs are often designed in a short space of time on a budget that may restrict the amount of money available to provide for other types of interface testing.\nIntroduction.\nThe main goal of heuristic evaluations is to identify any problems associated with the design of user interfaces. Usability consultants Rolf Molich and &lt;a href=\"Jakob%20Nielsen%20%28usability%20consultant%29\"&gt;Jakob Nielsen&lt;/a&gt; developed this method on the basis of several years of experience in teaching and consulting about &lt;a href=\"usability%20engineering\"&gt;usability engineering&lt;/a&gt;. &lt;a href=\"Heuristic\"&gt;Heuristic&lt;/a&gt; evaluations are one of the most informal methods of usability inspection in the field of &lt;a href=\"human%E2%80%93computer%20interaction\"&gt;human\u2013computer interaction&lt;/a&gt;. There are many sets of usability design heuristics; they are not mutually exclusive and cover many of the same aspects of user interface design. Quite often, usability problems that are discovered are categorized\u2014often on a numeric scale\u2014according to their estimated impact on user performance or acceptance. Often the heuristic evaluation is conducted in the context of &lt;a href=\"use%20cases\"&gt;use cases&lt;/a&gt; (typical user tasks), to provide &lt;a href=\"feedback\"&gt;feedback&lt;/a&gt; to the developers on the extent to which the interface is likely to be compatible with the intended users' needs and preferences.\nThe simplicity of heuristic evaluation is beneficial at the early stages of design and prior to user-based testing. This usability inspection method does not rely on users which can be burdensome due to the need for recruiting, scheduling issues, a place to perform the evaluation, and a payment for participant time. In the original report published, Nielsen stated that four experiments showed that individual evaluators were \"mostly quite bad\" at doing heuristic evaluations and suggested multiple evaluators were needed, with the results aggregated, to produce and to complete an acceptable review. Most heuristic evaluations can be accomplished in a matter of days. The time required varies with the size of the artifact, its complexity, the purpose of the review, the nature of the usability issues that arise in the review, and the competence of the reviewers. Using heuristic evaluation prior to user testing is often conducted to identify areas to be included in the evaluation or to eliminate perceived design issues prior to user-based evaluation.\nAlthough heuristic evaluation can uncover many major usability issues in a short period of time, a criticism that is often leveled is that results are highly influenced by the knowledge of the expert reviewer(s). This \"one-sided\" review repeatedly has different results than &lt;a href=\"software%20performance%20testing\"&gt;software performance testing&lt;/a&gt;, each type of testing uncovering a different set of problems.\nMethodology.\nHeuristic evaluation are conducted in variety of ways depending on the scope and type of project. As a general rule of thumb, there are researched frameworks involved to reduce bias and maximize findings within an evaluation.\nAmount of Evaluators.\nAccording to Nielsen, three to five evaluators are recommended within a study. Having more than five evaluators does not necessarily increase the amount of insights, and this may add more cost than benefit to the overall evaluation.\nIndividual and Group Process.\nHeuristic evaluation must start individually before aggregating results in order to reduce group confirmation bias. The evaluator should examine the prototype independently before entering group discussions to accumulate insights.\nObserver Trade-offs.\nThere are costs and benefits associated when adding an observer to an evaluation session. \nIn a session without an observer, evaluators would need to formalize their individual observations within a written report as they interact with the product/prototype. This option would require more time and effort from the evaluators, and this would also require further time for the conductors of the study to interpret individual reports. However, this option is less costly because it reduces the overhead costs associated with hiring observers. \nWith an observer, evaluators can provide their analysis verbally while observers transcribe and interpret the evaluators' findings. This option reduces the amount of workload from the evaluators and the amount of time needed to interpret findings from multiple evaluators.\nNielsen's heuristics.\n&lt;a href=\"Jakob%20Nielsen%20%28usability%20consultant%29\"&gt;Jakob Nielsen&lt;/a&gt;'s heuristics are probably the most-used usability heuristics for user interface design. Nielsen developed the heuristics based on work together with &lt;a href=\"Rolf%20Molich\"&gt;Rolf Molich&lt;/a&gt; in 1990. The final set of heuristics that are still used today were released by Nielsen in 1994. The heuristics as published in Nielsen's book \"Usability Engineering\" are as follows:\nGerhardt-Powals' cognitive engineering principles.\nAlthough Nielsen is considered the expert and field leader in heuristic evaluation, Jill Gerhardt-Powals developed a set of cognitive engineering principles for enhancing human-computer performance. These heuristics, or principles, are similar to Nielsen's heuristics but take a more holistic approach to evaluation. The Gerhardt Powals' principles are listed below.\nShneiderman's Eight Golden Rules of Interface Design.\n&lt;a href=\"Ben%20Shneiderman\"&gt;Ben Shneiderman&lt;/a&gt;'s book was published a few years prior to Nielsen, \"Designing the User Interface: Strategies for Effective Human-Computer Interaction\" (1986) covered his popular list of the, \"Eight Golden Rules\".\nWeinschenk and Barker classification.\nIn 2000, &lt;a href=\"Susan%20Weinschenk\"&gt;Susan Weinschenk&lt;/a&gt; and Dean Barker created a categorization of heuristics and guidelines used by several major providers into the following twenty types:\nDomain or culture-specific heuristic evaluation.\nFor an application with a specific domain and culture, the heuristics mentioned above do not identify the potential usability problems . These limitations of heuristics occur because these heuristics are incapable of considering the domain and culture-specific features of an application. This results in the introduction of domain-specific or culture-specific heuristic evaluation."
}